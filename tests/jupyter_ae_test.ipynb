{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trained-microwave",
   "metadata": {},
   "source": [
    "## Single-Task GP AE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ultimate-mention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "GP successfully initiated\n",
      "Costs successfully initialized\n",
      "##################################################################################\n",
      "Initialization successfully concluded\n",
      "now train(...) or train_async(...), and then go(...)\n",
      "##################################################################################\n",
      "GP training started with  10  data points\n",
      "Hyper-parameter tuning in progress. Old hyper-parameters:  [1. 1. 1.]  with old log likelihood:  10.573590826571358\n",
      "method:  global\n",
      "I am performing a global differential evolution algorithm to find the optimal hyperparameters.\n",
      "maximum number of iterations:  20\n",
      "termination tolerance:  1e-06\n",
      "bounds:  [[1.e-03 1.e+02]\n",
      " [1.e-03 1.e+02]\n",
      " [1.e-03 1.e+02]]\n",
      "differential_evolution step 1: f(x)= 10.478\n",
      "differential_evolution step 2: f(x)= 9.27054\n",
      "differential_evolution step 3: f(x)= 9.27054\n",
      "differential_evolution step 4: f(x)= 8.62985\n",
      "differential_evolution step 5: f(x)= 8.62985\n",
      "differential_evolution step 6: f(x)= 8.61251\n",
      "differential_evolution step 7: f(x)= 8.61251\n",
      "differential_evolution step 8: f(x)= 8.56158\n",
      "differential_evolution step 9: f(x)= 8.0078\n",
      "differential_evolution step 10: f(x)= 8.0078\n",
      "differential_evolution step 11: f(x)= 8.0078\n",
      "differential_evolution step 12: f(x)= 7.74615\n",
      "differential_evolution step 13: f(x)= 7.74615\n",
      "differential_evolution step 14: f(x)= 7.66444\n",
      "differential_evolution step 15: f(x)= 7.66444\n",
      "differential_evolution step 16: f(x)= 7.42903\n",
      "differential_evolution step 17: f(x)= 7.42903\n",
      "differential_evolution step 18: f(x)= 7.42903\n",
      "differential_evolution step 19: f(x)= 7.38666\n",
      "differential_evolution step 20: f(x)= 7.38666\n",
      "I found hyper-parameters  [0.31788517 6.2619162  1.44525934]  with likelihood  7.353945235381554  via global optimization\n",
      "Date and time:        2021-05-19_14_26_40\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  10\n",
      "Run Time:  0.0002613067626953125      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  1e-06\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.527114\n",
      "differential_evolution step 2: f(x)= -0.53126\n",
      "differential_evolution step 3: f(x)= -0.53126\n",
      "differential_evolution step 4: f(x)= -0.533557\n",
      "differential_evolution step 5: f(x)= -0.533751\n",
      "differential_evolution step 6: f(x)= -0.533751\n",
      "differential_evolution step 7: f(x)= -0.533751\n",
      "differential_evolution step 8: f(x)= -0.533751\n",
      "differential_evolution step 9: f(x)= -0.533751\n",
      "differential_evolution step 10: f(x)= -0.533751\n",
      "differential_evolution step 11: f(x)= -0.533769\n",
      "differential_evolution step 12: f(x)= -0.533812\n",
      "differential_evolution step 13: f(x)= -0.533812\n",
      "differential_evolution step 14: f(x)= -0.533815\n",
      "differential_evolution step 15: f(x)= -0.533815\n",
      "differential_evolution step 16: f(x)= -0.533816\n",
      "differential_evolution step 17: f(x)= -0.533816\n",
      "differential_evolution step 18: f(x)= -0.533816\n",
      "differential_evolution step 19: f(x)= -0.533824\n",
      "differential_evolution step 20: f(x)= -0.533824\n",
      "variance optimization tolerance of changed to:  0.05338238625971135\n",
      "Next points to be requested: \n",
      "[[9.99986864 2.65066543]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  11\n",
      "Run Time:  0.15100622177124023      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05338238625971135\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.052896287503701504\n",
      "Next points to be requested: \n",
      "[[9.34564811 2.72471347]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  12\n",
      "Run Time:  0.15553784370422363      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.052896287503701504\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.530204\n",
      "differential_evolution step 2: f(x)= -0.530204\n",
      "differential_evolution step 3: f(x)= -0.530204\n",
      "differential_evolution step 4: f(x)= -0.532358\n",
      "variance optimization tolerance of changed to:  0.05323578226764464\n",
      "Next points to be requested: \n",
      "[[9.79554146 2.65043323]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  13\n",
      "Run Time:  0.1994490623474121      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05323578226764464\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04392268798861257\n",
      "Next points to be requested: \n",
      "[[6.23456521 1.2693377 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  14\n",
      "Run Time:  0.20356965065002441      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04392268798861257\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.527311\n",
      "differential_evolution step 2: f(x)= -0.530263\n",
      "differential_evolution step 3: f(x)= -0.53325\n",
      "differential_evolution step 4: f(x)= -0.53325\n",
      "differential_evolution step 5: f(x)= -0.53325\n",
      "variance optimization tolerance of changed to:  0.05332497452498311\n",
      "Next points to be requested: \n",
      "[[9.68518197 0.08339551]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  15\n",
      "Run Time:  0.24813294410705566      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05332497452498311\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.045910479314976736\n",
      "Next points to be requested: \n",
      "[[0.41391097 7.49619533]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  16\n",
      "Run Time:  0.2530965805053711      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.045910479314976736\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.528935\n",
      "differential_evolution step 2: f(x)= -0.529942\n",
      "differential_evolution step 3: f(x)= -0.531223\n",
      "variance optimization tolerance of changed to:  0.05312231963031783\n",
      "Next points to be requested: \n",
      "[[9.69073288 2.86095883]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  17\n",
      "Run Time:  0.2842700481414795      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05312231963031783\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04112884236945916\n",
      "Next points to be requested: \n",
      "[[3.35685005 5.96770687]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  18\n",
      "Run Time:  0.2897303104400635      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04112884236945916\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.531523\n",
      "differential_evolution step 2: f(x)= -0.532307\n",
      "differential_evolution step 3: f(x)= -0.532307\n",
      "differential_evolution step 4: f(x)= -0.53415\n",
      "differential_evolution step 5: f(x)= -0.53415\n",
      "differential_evolution step 6: f(x)= -0.53415\n",
      "variance optimization tolerance of changed to:  0.05341496010282115\n",
      "Next points to be requested: \n",
      "[[9.86042733 0.11472942]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  19\n",
      "Run Time:  0.35964345932006836      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05341496010282115\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.045602826450763995\n",
      "Next points to be requested: \n",
      "[[2.36059425 4.02607662]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  20\n",
      "Run Time:  0.3658907413482666      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.045602826450763995\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.530368\n",
      "differential_evolution step 2: f(x)= -0.530368\n",
      "differential_evolution step 3: f(x)= -0.530523\n",
      "differential_evolution step 4: f(x)= -0.534877\n",
      "variance optimization tolerance of changed to:  0.05348773707113809\n",
      "Next points to be requested: \n",
      "[[9.94514895 0.11442113]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  21\n",
      "Run Time:  0.4196934700012207      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05348773707113809\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.049234046561344835\n",
      "Next points to be requested: \n",
      "[[9.87087102 9.67353375]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  22\n",
      "Run Time:  0.4277627468109131      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.049234046561344835\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.529034\n",
      "differential_evolution step 2: f(x)= -0.529034\n",
      "differential_evolution step 3: f(x)= -0.532668\n",
      "differential_evolution step 4: f(x)= -0.532775\n",
      "variance optimization tolerance of changed to:  0.05327745478614498\n",
      "Next points to be requested: \n",
      "[[9.92576484 2.42688964]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  23\n",
      "Run Time:  0.4888031482696533      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05327745478614498\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04124165756790134\n",
      "Next points to be requested: \n",
      "[[6.30081906 4.15556886]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  24\n",
      "Run Time:  0.49508094787597656      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04124165756790134\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.53315\n",
      "differential_evolution step 2: f(x)= -0.53315\n",
      "differential_evolution step 3: f(x)= -0.53315\n",
      "differential_evolution step 4: f(x)= -0.53315\n",
      "differential_evolution step 5: f(x)= -0.53315\n",
      "differential_evolution step 6: f(x)= -0.53315\n",
      "variance optimization tolerance of changed to:  0.05331501072917738\n",
      "Next points to be requested: \n",
      "[[9.97918769 0.22719621]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  25\n",
      "Run Time:  0.5604133605957031      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05331501072917738\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0389087752316431\n",
      "Next points to be requested: \n",
      "[[4.04813971 7.78912837]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  26\n",
      "Run Time:  0.5650782585144043      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.0389087752316431\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.528556\n",
      "differential_evolution step 2: f(x)= -0.528556\n",
      "differential_evolution step 3: f(x)= -0.531063\n",
      "differential_evolution step 4: f(x)= -0.53305\n",
      "variance optimization tolerance of changed to:  0.05330499385569568\n",
      "Next points to be requested: \n",
      "[[9.89062094 2.67737979]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  27\n",
      "Run Time:  0.6024529933929443      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05330499385569568\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0419416699349003\n",
      "Next points to be requested: \n",
      "[[5.82146371 0.65367999]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  28\n",
      "Run Time:  0.6069447994232178      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.0419416699349003\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.533588\n",
      "differential_evolution step 2: f(x)= -0.533588\n",
      "differential_evolution step 3: f(x)= -0.533588\n",
      "differential_evolution step 4: f(x)= -0.533588\n",
      "differential_evolution step 5: f(x)= -0.533588\n",
      "variance optimization tolerance of changed to:  0.053358760245181075\n",
      "Next points to be requested: \n",
      "[[9.9869252  2.77382699]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  29\n",
      "Run Time:  0.6502652168273926      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053358760245181075\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04925015684042549\n",
      "Next points to be requested: \n",
      "[[0.44049771 9.51828879]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  30\n",
      "Run Time:  0.6548490524291992      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04925015684042549\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.527031\n",
      "differential_evolution step 2: f(x)= -0.531611\n",
      "differential_evolution step 3: f(x)= -0.532953\n",
      "variance optimization tolerance of changed to:  0.053295328269546374\n",
      "Next points to be requested: \n",
      "[[9.88433555 2.73724235]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  31\n",
      "Run Time:  0.6858999729156494      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053295328269546374\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.051763101423400786\n",
      "Next points to be requested: \n",
      "[[8.16085939 3.06107405]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  32\n",
      "Run Time:  0.689934492111206      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.051763101423400786\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.522879\n",
      "differential_evolution step 2: f(x)= -0.528521\n",
      "differential_evolution step 3: f(x)= -0.528521\n",
      "differential_evolution step 4: f(x)= -0.532454\n",
      "variance optimization tolerance of changed to:  0.05324538116733483\n",
      "Next points to be requested: \n",
      "[[9.83187986 2.54288337]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  33\n",
      "Run Time:  0.7320423126220703      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05324538116733483\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04243725270955789\n",
      "Next points to be requested: \n",
      "[[6.67786561 6.21216461]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  34\n",
      "Run Time:  0.7367615699768066      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04243725270955789\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.530783\n",
      "differential_evolution step 2: f(x)= -0.530783\n",
      "differential_evolution step 3: f(x)= -0.530783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 4: f(x)= -0.533506\n",
      "variance optimization tolerance of changed to:  0.053350628351678864\n",
      "Next points to be requested: \n",
      "[[9.95543403 2.68306641]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  35\n",
      "Run Time:  0.791628360748291      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053350628351678864\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.037432333198236696\n",
      "Next points to be requested: \n",
      "[[5.6592789  7.98456411]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  36\n",
      "Run Time:  0.7986493110656738      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.037432333198236696\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.532527\n",
      "differential_evolution step 2: f(x)= -0.53277\n",
      "differential_evolution step 3: f(x)= -0.53277\n",
      "differential_evolution step 4: f(x)= -0.533239\n",
      "differential_evolution step 5: f(x)= -0.533753\n",
      "variance optimization tolerance of changed to:  0.05337528305966023\n",
      "Next points to be requested: \n",
      "[[9.99141535 2.62226636]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  37\n",
      "Run Time:  0.8752729892730713      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05337528305966023\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.048633759381013476\n",
      "Next points to be requested: \n",
      "[[0.17136583 4.49413053]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  38\n",
      "Run Time:  0.8800516128540039      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.048633759381013476\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.532178\n",
      "differential_evolution step 2: f(x)= -0.532178\n",
      "differential_evolution step 3: f(x)= -0.533313\n",
      "differential_evolution step 4: f(x)= -0.533562\n",
      "differential_evolution step 5: f(x)= -0.533562\n",
      "variance optimization tolerance of changed to:  0.05335615635003746\n",
      "Next points to be requested: \n",
      "[[9.97379291 2.74502299]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  39\n",
      "Run Time:  0.923882246017456      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05335615635003746\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03976961490694596\n",
      "Next points to be requested: \n",
      "[[7.68313085 6.91913862]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  40\n",
      "Run Time:  0.9296143054962158      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.03976961490694596\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.525893\n",
      "differential_evolution step 2: f(x)= -0.525893\n",
      "differential_evolution step 3: f(x)= -0.533351\n",
      "differential_evolution step 4: f(x)= -0.533786\n",
      "differential_evolution step 5: f(x)= -0.533786\n",
      "variance optimization tolerance of changed to:  0.05337858548205935\n",
      "Next points to be requested: \n",
      "[[9.99961579 2.71523199]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  41\n",
      "Run Time:  0.9747605323791504      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05337858548205935\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04636897927481768\n",
      "Next points to be requested: \n",
      "[[8.89755194 9.56508399]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  42\n",
      "Run Time:  0.9799160957336426      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04636897927481768\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.523304\n",
      "differential_evolution step 2: f(x)= -0.530173\n",
      "differential_evolution step 3: f(x)= -0.532484\n",
      "differential_evolution step 4: f(x)= -0.532484\n",
      "variance optimization tolerance of changed to:  0.05324837609808645\n",
      "Next points to be requested: \n",
      "[[9.98766052 2.98483645]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  43\n",
      "Run Time:  1.0179400444030762      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05324837609808645\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.031531672594166095\n",
      "Next points to be requested: \n",
      "[[8.12846929 7.56664019]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  44\n",
      "Run Time:  1.0227046012878418      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.031531672594166095\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.533024\n",
      "differential_evolution step 2: f(x)= -0.533024\n",
      "differential_evolution step 3: f(x)= -0.533024\n",
      "differential_evolution step 4: f(x)= -0.533024\n",
      "differential_evolution step 5: f(x)= -0.533024\n",
      "variance optimization tolerance of changed to:  0.05330238115127222\n",
      "Next points to be requested: \n",
      "[[9.90373267 2.55645701]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  45\n",
      "Run Time:  1.0672907829284668      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05330238115127222\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04116892576491707\n",
      "Next points to be requested: \n",
      "[[4.84415647 9.98877915]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  46\n",
      "Run Time:  1.0715913772583008      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04116892576491707\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.534781\n",
      "differential_evolution step 2: f(x)= -0.534781\n",
      "differential_evolution step 3: f(x)= -0.534781\n",
      "differential_evolution step 4: f(x)= -0.534781\n",
      "differential_evolution step 5: f(x)= -0.534781\n",
      "variance optimization tolerance of changed to:  0.05347810743950096\n",
      "Next points to be requested: \n",
      "[[9.75950251 0.03960094]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  47\n",
      "Run Time:  1.11859130859375      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05347810743950096\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03805775351195758\n",
      "Next points to be requested: \n",
      "[[0.698066   1.26747501]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  48\n",
      "Run Time:  1.1233935356140137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.03805775351195758\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.529799\n",
      "differential_evolution step 2: f(x)= -0.529799\n",
      "differential_evolution step 3: f(x)= -0.531987\n",
      "differential_evolution step 4: f(x)= -0.533054\n",
      "differential_evolution step 5: f(x)= -0.533054\n",
      "variance optimization tolerance of changed to:  0.05330537628884097\n",
      "Next points to be requested: \n",
      "[[9.9351602  2.83009767]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  49\n",
      "Run Time:  1.1690952777862549      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05330537628884097\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03758083633044961\n",
      "Next points to be requested: \n",
      "[[5.54197293 7.9438693 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  50\n",
      "Run Time:  1.1764540672302246      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.03758083633044961\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.531498\n",
      "differential_evolution step 2: f(x)= -0.531498\n",
      "differential_evolution step 3: f(x)= -0.531498\n",
      "differential_evolution step 4: f(x)= -0.532954\n",
      "differential_evolution step 5: f(x)= -0.533372\n",
      "differential_evolution step 6: f(x)= -0.533694\n",
      "variance optimization tolerance of changed to:  0.05336943575232292\n",
      "Next points to be requested: \n",
      "[[9.99658487 2.55147094]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  51\n",
      "Run Time:  1.2283670902252197      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05336943575232292\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.051040568146179945\n",
      "Next points to be requested: \n",
      "[[8.85088541 0.7053702 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  52\n",
      "Run Time:  1.233262538909912      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.051040568146179945\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.530508\n",
      "differential_evolution step 2: f(x)= -0.53232\n",
      "differential_evolution step 3: f(x)= -0.53232\n",
      "variance optimization tolerance of changed to:  0.053231953657582154\n",
      "Next points to be requested: \n",
      "[[9.80956888 2.55662188]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  53\n",
      "Run Time:  1.2750627994537354      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053231953657582154\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04068784359673842\n",
      "Next points to be requested: \n",
      "[[8.63842447 8.66611525]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  54\n",
      "Run Time:  1.2872331142425537      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04068784359673842\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.530658\n",
      "differential_evolution step 2: f(x)= -0.530658\n",
      "differential_evolution step 3: f(x)= -0.532525\n",
      "differential_evolution step 4: f(x)= -0.532525\n",
      "differential_evolution step 5: f(x)= -0.532525\n",
      "variance optimization tolerance of changed to:  0.05325254910619849\n",
      "Next points to be requested: \n",
      "[[9.81758838 2.67189502]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  55\n",
      "Run Time:  1.3688673973083496      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05325254910619849\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04200500084138085\n",
      "Next points to be requested: \n",
      "[[9.42045    8.45222368]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  56\n",
      "Run Time:  1.3748095035552979      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04200500084138085\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.532047\n",
      "differential_evolution step 2: f(x)= -0.534212\n",
      "differential_evolution step 3: f(x)= -0.534212\n",
      "differential_evolution step 4: f(x)= -0.534212\n",
      "differential_evolution step 5: f(x)= -0.534212\n",
      "variance optimization tolerance of changed to:  0.05342116896791191\n",
      "Next points to be requested: \n",
      "[[9.9946411  0.17459267]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  57\n",
      "Run Time:  1.421086311340332      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05342116896791191\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.038809315728523974\n",
      "Next points to be requested: \n",
      "[[1.8376174 7.0387611]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  58\n",
      "Run Time:  1.426215410232544      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.038809315728523974\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.527865\n",
      "differential_evolution step 2: f(x)= -0.531547\n",
      "differential_evolution step 3: f(x)= -0.531547\n",
      "differential_evolution step 4: f(x)= -0.531954\n",
      "differential_evolution step 5: f(x)= -0.531954\n",
      "differential_evolution step 6: f(x)= -0.531954\n",
      "variance optimization tolerance of changed to:  0.05319539435577397\n",
      "Next points to be requested: \n",
      "[[9.73945994 2.66991003]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  59\n",
      "Run Time:  1.4813098907470703      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05319539435577397\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.051658315233431645\n",
      "Next points to be requested: \n",
      "[[9.06226311 0.53544737]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  60\n",
      "Run Time:  1.4864461421966553      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.051658315233431645\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.529996\n",
      "differential_evolution step 2: f(x)= -0.532875\n",
      "differential_evolution step 3: f(x)= -0.532875\n",
      "differential_evolution step 4: f(x)= -0.533296\n",
      "variance optimization tolerance of changed to:  0.05332963643340832\n",
      "Next points to be requested: \n",
      "[[9.93377993 2.58452203]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  61\n",
      "Run Time:  1.5249345302581787      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05332963643340832\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.046949995629635526\n",
      "Next points to be requested: \n",
      "[[8.88737274 4.28066089]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  62\n",
      "Run Time:  1.5308544635772705      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.046949995629635526\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.532039\n",
      "differential_evolution step 2: f(x)= -0.532039\n",
      "differential_evolution step 3: f(x)= -0.532039\n",
      "differential_evolution step 4: f(x)= -0.533277\n",
      "differential_evolution step 5: f(x)= -0.534976\n",
      "variance optimization tolerance of changed to:  0.053497643970219846\n",
      "Next points to be requested: \n",
      "[[9.93417764 0.10413187]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  63\n",
      "Run Time:  1.5759718418121338      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053497643970219846\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04196866983302976\n",
      "Next points to be requested: \n",
      "[[2.95315854 5.71759227]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  64\n",
      "Run Time:  1.5813016891479492      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04196866983302976\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.531302\n",
      "differential_evolution step 2: f(x)= -0.53144\n",
      "differential_evolution step 3: f(x)= -0.531897\n",
      "differential_evolution step 4: f(x)= -0.53211\n",
      "differential_evolution step 5: f(x)= -0.533528\n",
      "variance optimization tolerance of changed to:  0.053352786422602355\n",
      "Next points to be requested: \n",
      "[[9.97841041 2.53571454]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  65\n",
      "Run Time:  1.655418872833252      seconds\n",
      "Number of measurements:  10\n",
      "====================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053352786422602355\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.050139665698341385\n",
      "Next points to be requested: \n",
      "[[7.42630616 3.4527112 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  66\n",
      "Run Time:  1.6861176490783691      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.050139665698341385\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.529992\n",
      "differential_evolution step 2: f(x)= -0.53109\n",
      "differential_evolution step 3: f(x)= -0.53109\n",
      "differential_evolution step 4: f(x)= -0.532392\n",
      "variance optimization tolerance of changed to:  0.05323921461652231\n",
      "Next points to be requested: \n",
      "[[9.8057299  2.74073828]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  67\n",
      "Run Time:  1.7391674518585205      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05323921461652231\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.051546078137647056\n",
      "Next points to be requested: \n",
      "[[9.23070173 3.55276315]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  68\n",
      "Run Time:  1.7462670803070068      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.051546078137647056\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.529833\n",
      "differential_evolution step 2: f(x)= -0.532877\n",
      "differential_evolution step 3: f(x)= -0.532877\n",
      "differential_evolution step 4: f(x)= -0.532877\n",
      "variance optimization tolerance of changed to:  0.053287691424192186\n",
      "Next points to be requested: \n",
      "[[9.8664773  2.65935775]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  69\n",
      "Run Time:  1.7850255966186523      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053287691424192186\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.052498600444271196\n",
      "Next points to be requested: \n",
      "[[9.12679869 2.3142073 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  70\n",
      "Run Time:  1.7898640632629395      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.052498600444271196\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.518317\n",
      "differential_evolution step 2: f(x)= -0.52956\n",
      "differential_evolution step 3: f(x)= -0.52956\n",
      "differential_evolution step 4: f(x)= -0.533393\n",
      "differential_evolution step 5: f(x)= -0.533393\n",
      "variance optimization tolerance of changed to:  0.05333931344619794\n",
      "Next points to be requested: \n",
      "[[9.97914965 2.8194031 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  71\n",
      "Run Time:  1.835637092590332      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05333931344619794\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03143559111330269\n",
      "Next points to be requested: \n",
      "[[5.80745319 5.17357322]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  72\n",
      "Run Time:  1.8410754203796387      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.03143559111330269\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.526262\n",
      "differential_evolution step 2: f(x)= -0.533371\n",
      "differential_evolution step 3: f(x)= -0.533371\n",
      "differential_evolution step 4: f(x)= -0.533371\n",
      "differential_evolution step 5: f(x)= -0.533371\n",
      "differential_evolution step 6: f(x)= -0.533691\n",
      "variance optimization tolerance of changed to:  0.0533690661696434\n",
      "Next points to be requested: \n",
      "[[9.88214285 0.14892502]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  73\n",
      "Run Time:  1.8958983421325684      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.0533690661696434\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03073455382113051\n",
      "Next points to be requested: \n",
      "[[8.29455821 7.65459232]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  74\n",
      "Run Time:  1.9023311138153076      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.03073455382113051\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.525654\n",
      "differential_evolution step 2: f(x)= -0.527423\n",
      "differential_evolution step 3: f(x)= -0.532065\n",
      "differential_evolution step 4: f(x)= -0.533477\n",
      "differential_evolution step 5: f(x)= -0.533477\n",
      "differential_evolution step 6: f(x)= -0.533477\n",
      "variance optimization tolerance of changed to:  0.0533476786516045\n",
      "Next points to be requested: \n",
      "[[9.98575041 2.80836846]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  75\n",
      "Run Time:  1.9567348957061768      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.0533476786516045\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.045448182210031336\n",
      "Next points to be requested: \n",
      "[[2.02573011 8.5622144 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  76\n",
      "Run Time:  1.9620373249053955      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.045448182210031336\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.529256\n",
      "differential_evolution step 2: f(x)= -0.529256\n",
      "differential_evolution step 3: f(x)= -0.529854\n",
      "variance optimization tolerance of changed to:  0.052985356278393785\n",
      "Next points to be requested: \n",
      "[[9.54721466 2.45623766]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  77\n",
      "Run Time:  1.9927120208740234      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.052985356278393785\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04912509356547559\n",
      "Next points to be requested: \n",
      "[[0.12670874 4.30059256]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  78\n",
      "Run Time:  1.9973564147949219      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04912509356547559\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.52936\n",
      "differential_evolution step 2: f(x)= -0.52936\n",
      "differential_evolution step 3: f(x)= -0.533035\n",
      "differential_evolution step 4: f(x)= -0.533822\n",
      "differential_evolution step 5: f(x)= -0.53704\n",
      "variance optimization tolerance of changed to:  0.053703976415075155\n",
      "Next points to be requested: \n",
      "[[9.98983806 0.01725462]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  79\n",
      "Run Time:  2.043259382247925      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053703976415075155\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.047943009790696184\n",
      "Next points to be requested: \n",
      "[[3.6672322  3.37399025]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  80\n",
      "Run Time:  2.049602746963501      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.047943009790696184\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.533027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 2: f(x)= -0.533027\n",
      "differential_evolution step 3: f(x)= -0.533027\n",
      "variance optimization tolerance of changed to:  0.05330267367320793\n",
      "Next points to be requested: \n",
      "[[9.93120561 2.8301087 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  81\n",
      "Run Time:  2.0805978775024414      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05330267367320793\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03978320046072412\n",
      "Next points to be requested: \n",
      "[[1.68304434 0.52760257]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  82\n",
      "Run Time:  2.0863914489746094      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.03978320046072412\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.533065\n",
      "differential_evolution step 2: f(x)= -0.533065\n",
      "differential_evolution step 3: f(x)= -0.533065\n",
      "differential_evolution step 4: f(x)= -0.533065\n",
      "variance optimization tolerance of changed to:  0.05330647829111086\n",
      "Next points to be requested: \n",
      "[[9.95661122 2.86143177]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  83\n",
      "Run Time:  2.129723072052002      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05330647829111086\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03866446830321753\n",
      "Next points to be requested: \n",
      "[[4.28600259 5.3261077 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  84\n",
      "Run Time:  2.1403987407684326      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.03866446830321753\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.528526\n",
      "differential_evolution step 2: f(x)= -0.528975\n",
      "differential_evolution step 3: f(x)= -0.535546\n",
      "differential_evolution step 4: f(x)= -0.535546\n",
      "differential_evolution step 5: f(x)= -0.535546\n",
      "differential_evolution step 6: f(x)= -0.535995\n",
      "variance optimization tolerance of changed to:  0.05359946260601001\n",
      "Next points to be requested: \n",
      "[[9.88979751 0.03147249]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  85\n",
      "Run Time:  2.2328906059265137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05359946260601001\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04821506256651436\n",
      "Next points to be requested: \n",
      "[[2.01684802 3.45830072]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  86\n",
      "Run Time:  2.2376222610473633      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04821506256651436\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.53171\n",
      "differential_evolution step 2: f(x)= -0.53171\n",
      "differential_evolution step 3: f(x)= -0.532377\n",
      "differential_evolution step 4: f(x)= -0.533166\n",
      "differential_evolution step 5: f(x)= -0.533166\n",
      "variance optimization tolerance of changed to:  0.05331661479393055\n",
      "Next points to be requested: \n",
      "[[9.94905361 2.48417201]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  87\n",
      "Run Time:  2.2856969833374023      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05331661479393055\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04997882290006897\n",
      "Next points to be requested: \n",
      "[[0.03603714 3.62875047]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  88\n",
      "Run Time:  2.2906970977783203      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04997882290006897\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.5327\n",
      "differential_evolution step 2: f(x)= -0.5327\n",
      "differential_evolution step 3: f(x)= -0.5327\n",
      "differential_evolution step 4: f(x)= -0.5327\n",
      "variance optimization tolerance of changed to:  0.05326998512551835\n",
      "Next points to be requested: \n",
      "[[9.96081899 2.93105246]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  89\n",
      "Run Time:  2.3432350158691406      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05326998512551835\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04489410394971649\n",
      "Next points to be requested: \n",
      "[[9.66568428 6.63176053]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  90\n",
      "Run Time:  2.3509597778320312      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04489410394971649\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.531277\n",
      "differential_evolution step 2: f(x)= -0.531277\n",
      "differential_evolution step 3: f(x)= -0.531277\n",
      "differential_evolution step 4: f(x)= -0.531277\n",
      "differential_evolution step 5: f(x)= -0.532011\n",
      "variance optimization tolerance of changed to:  0.0532011247645945\n",
      "Next points to be requested: \n",
      "[[9.82427695 0.21031114]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  91\n",
      "Run Time:  2.3965258598327637      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.0532011247645945\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04865515978657747\n",
      "Next points to be requested: \n",
      "[[0.9541566  0.02185239]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  92\n",
      "Run Time:  2.4014666080474854      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04865515978657747\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.530581\n",
      "differential_evolution step 2: f(x)= -0.530889\n",
      "differential_evolution step 3: f(x)= -0.532323\n",
      "variance optimization tolerance of changed to:  0.053232270703046126\n",
      "Next points to be requested: \n",
      "[[9.88854203 2.39152774]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  93\n",
      "Run Time:  2.4323484897613525      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053232270703046126\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04799463226524741\n",
      "Next points to be requested: \n",
      "[[1.15610798 4.02928482]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  94\n",
      "Run Time:  2.439063310623169      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.04799463226524741\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.522186\n",
      "differential_evolution step 2: f(x)= -0.531862\n",
      "differential_evolution step 3: f(x)= -0.53227\n",
      "differential_evolution step 4: f(x)= -0.53227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance optimization tolerance of changed to:  0.053227026899654445\n",
      "Next points to be requested: \n",
      "[[9.78258566 2.68807425]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  95\n",
      "Run Time:  2.477940082550049      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.053227026899654445\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.041993997776099315\n",
      "Next points to be requested: \n",
      "[[6.33387936 6.14276372]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  96\n",
      "Run Time:  2.4865238666534424      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.041993997776099315\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.5337\n",
      "differential_evolution step 2: f(x)= -0.5337\n",
      "differential_evolution step 3: f(x)= -0.5337\n",
      "differential_evolution step 4: f(x)= -0.5337\n",
      "differential_evolution step 5: f(x)= -0.5337\n",
      "differential_evolution step 6: f(x)= -0.5337\n",
      "differential_evolution step 7: f(x)= -0.5337\n",
      "variance optimization tolerance of changed to:  0.05336997369542913\n",
      "Next points to be requested: \n",
      "[[9.99491345 2.74852348]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  97\n",
      "Run Time:  2.5878727436065674      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.05336997369542913\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.052116409703126615\n",
      "Next points to be requested: \n",
      "[[9.17803872 3.3393336 ]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  98\n",
      "Run Time:  2.5936074256896973      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "tolerance:  0.052116409703126615\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.526399\n",
      "differential_evolution step 2: f(x)= -0.53117\n",
      "differential_evolution step 3: f(x)= -0.532578\n",
      "differential_evolution step 4: f(x)= -0.53305\n",
      "variance optimization tolerance of changed to:  0.0533049846962953\n",
      "Next points to be requested: \n",
      "[[9.9024806  2.75441769]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  99\n",
      "Run Time:  2.632401943206787      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.31788517 6.2619162  1.44525934]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "tolerance:  0.0533049846962953\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.038445125472834026\n",
      "Next points to be requested: \n",
      "[[8.33001252 4.90648224]]\n",
      "Training ...\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.31788517 6.2619162  1.44525934]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "====================================================\n",
      "The autonomous experiment was concluded successfully\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "#/usr/bin/env python\n",
    "import numpy as np\n",
    "from gpcam.autonomous_experimenter import AutonomousExperimenterGP\n",
    "\n",
    "def instrument(data):\n",
    "    for entry in data:\n",
    "        entry[\"value\"] = np.sin(np.linalg.norm(entry[\"position\"]))\n",
    "    return data\n",
    "\n",
    "my_ae = AutonomousExperimenterGP(np.array([[0,10],[0,10]]),instrument,\n",
    "                                 np.ones((3)),np.array([[0.001,100],[0.001,100],[0.001,100]]),\n",
    "                                 init_dataset_size= 10)\n",
    "my_ae.train()\n",
    "my_ae.go(N = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-rings",
   "metadata": {},
   "source": [
    "## Multi-Task GP AE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "italian-worth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAUTION: you have not provided data variances, they will set to be 1 percent of the data values!\n",
      "Costs successfully initialized\n",
      "##################################################################################\n",
      "Initialization successfully concluded\n",
      "now train(...) or train_async(...), and then go(...)\n",
      "##################################################################################\n",
      "GP training started with  20  data points\n",
      "Hyper-parameter tuning in progress. Old hyper-parameters:  [1. 1. 1.]  with old log likelihood:  nan\n",
      "method:  global\n",
      "I am performing a global differential evolution algorithm to find the optimal hyperparameters.\n",
      "maximum number of iterations:  20\n",
      "termination tolerance:  1e-06\n",
      "bounds:  [[1.e-03 1.e+02]\n",
      " [1.e-03 1.e+02]\n",
      " [1.e-03 1.e+02]]\n",
      "differential_evolution step 1: f(x)= nan\n",
      "differential_evolution step 2: f(x)= nan\n",
      "differential_evolution step 3: f(x)= nan\n",
      "differential_evolution step 4: f(x)= nan\n",
      "differential_evolution step 5: f(x)= nan\n",
      "differential_evolution step 6: f(x)= nan\n",
      "differential_evolution step 7: f(x)= nan\n",
      "differential_evolution step 8: f(x)= nan\n",
      "differential_evolution step 9: f(x)= nan\n",
      "differential_evolution step 10: f(x)= nan\n",
      "differential_evolution step 11: f(x)= nan\n",
      "differential_evolution step 12: f(x)= nan\n",
      "differential_evolution step 13: f(x)= nan\n",
      "differential_evolution step 14: f(x)= nan\n",
      "differential_evolution step 15: f(x)= nan\n",
      "differential_evolution step 16: f(x)= nan\n",
      "differential_evolution step 17: f(x)= nan\n",
      "differential_evolution step 18: f(x)= nan\n",
      "differential_evolution step 19: f(x)= nan\n",
      "differential_evolution step 20: f(x)= nan\n",
      "I found hyper-parameters  [ 4.58490202 71.11226116 66.9284315 ]  with likelihood  nan  via global optimization\n",
      "training done\n",
      "Date and time:        2021-05-17_15_11_08\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  10\n",
      "Run Time:  0.0004107952117919922      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  1e-06\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666949\n",
      "differential_evolution step 2: f(x)= -0.666949\n",
      "differential_evolution step 3: f(x)= -0.666949\n",
      "differential_evolution step 4: f(x)= -0.666949\n",
      "differential_evolution step 5: f(x)= -0.666949\n",
      "differential_evolution step 6: f(x)= -0.666949\n",
      "differential_evolution step 7: f(x)= -0.666949\n",
      "differential_evolution step 8: f(x)= -0.666949\n",
      "differential_evolution step 9: f(x)= -0.666949\n",
      "differential_evolution step 10: f(x)= -0.666949\n",
      "differential_evolution step 11: f(x)= -0.666949\n",
      "differential_evolution step 12: f(x)= -0.666949\n",
      "differential_evolution step 13: f(x)= -0.666949\n",
      "differential_evolution step 14: f(x)= -0.667011\n",
      "differential_evolution step 15: f(x)= -0.667011\n",
      "differential_evolution step 16: f(x)= -0.667064\n",
      "differential_evolution step 17: f(x)= -0.667064\n",
      "differential_evolution step 18: f(x)= -0.667248\n",
      "differential_evolution step 19: f(x)= -0.667248\n",
      "differential_evolution step 20: f(x)= -0.667248\n",
      "variance optimization tolerance of changed to:  0.06672477504296123\n",
      "Next points to be requested: \n",
      "[[9.96385706e+00 1.45499768e-03]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  11\n",
      "Run Time:  0.18946552276611328      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06672477504296123\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06326788034067214\n",
      "Next points to be requested: \n",
      "[[5.03721849 3.37448214]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  12\n",
      "Run Time:  0.19803357124328613      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06326788034067214\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665317\n",
      "differential_evolution step 2: f(x)= -0.665317\n",
      "variance optimization tolerance of changed to:  0.06653173310939929\n",
      "Next points to be requested: \n",
      "[[9.44799596 2.46982538]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  13\n",
      "Run Time:  0.22661042213439941      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06653173310939929\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.063763393695835\n",
      "Next points to be requested: \n",
      "[[2.7193728  8.74242528]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  14\n",
      "Run Time:  0.23637962341308594      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.063763393695835\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663714\n",
      "variance optimization tolerance of changed to:  0.06637135656439169\n",
      "Next points to be requested: \n",
      "[[8.98314738 2.40425369]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  15\n",
      "Run Time:  0.25820112228393555      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06637135656439169\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.060281966852425\n",
      "Next points to be requested: \n",
      "[[6.02068589 7.41967909]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  16\n",
      "Run Time:  0.26535654067993164      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.060281966852425\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666212\n",
      "differential_evolution step 2: f(x)= -0.666212\n",
      "variance optimization tolerance of changed to:  0.06662122554586679\n",
      "Next points to be requested: \n",
      "[[9.90947893 2.45032126]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  17\n",
      "Run Time:  0.2960629463195801      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06662122554586679\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.061783119993249584\n",
      "Next points to be requested: \n",
      "[[6.11569815 7.59470084]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  18\n",
      "Run Time:  0.3042111396789551      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.061783119993249584\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663317\n",
      "differential_evolution step 2: f(x)= -0.664177\n",
      "variance optimization tolerance of changed to:  0.06641769627759592\n",
      "Next points to be requested: \n",
      "[[8.75345469 2.5455443 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  19\n",
      "Run Time:  0.32880663871765137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06641769627759592\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.060365713612159345\n",
      "Next points to be requested: \n",
      "[[5.35122785 1.77879114]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  20\n",
      "Run Time:  0.33699893951416016      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.060365713612159345\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666112\n",
      "differential_evolution step 2: f(x)= -0.666112\n",
      "differential_evolution step 3: f(x)= -0.666112\n",
      "variance optimization tolerance of changed to:  0.06661120651073982\n",
      "Next points to be requested: \n",
      "[[9.94243593 0.08657951]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  21\n",
      "Run Time:  0.3721926212310791      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06661120651073982\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06169077304992319\n",
      "Next points to be requested: \n",
      "[[8.42458318 8.24078567]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  22\n",
      "Run Time:  0.38024473190307617      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06169077304992319\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663005\n",
      "variance optimization tolerance of changed to:  0.06630052151903129\n",
      "Next points to be requested: \n",
      "[[8.29247585 2.79703065]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  23\n",
      "Run Time:  0.399289608001709      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06630052151903129\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06594051913544112\n",
      "Next points to be requested: \n",
      "[[7.54994542 2.96388611]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  24\n",
      "Run Time:  0.4075009822845459      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06594051913544112\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.664867\n",
      "differential_evolution step 2: f(x)= -0.665637\n",
      "variance optimization tolerance of changed to:  0.06656368341489503\n",
      "Next points to be requested: \n",
      "[[9.39524063 2.60115416]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  25\n",
      "Run Time:  0.43551015853881836      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656368341489503\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06442513007643091\n",
      "Next points to be requested: \n",
      "[[6.66293562 2.06582047]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  26\n",
      "Run Time:  0.44260668754577637      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06442513007643091\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664265\n",
      "differential_evolution step 2: f(x)= -0.664265\n",
      "variance optimization tolerance of changed to:  0.06642650959780513\n",
      "Next points to be requested: \n",
      "[[8.93818836 2.48657745]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  27\n",
      "Run Time:  0.4687504768371582      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642650959780513\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05578856358301263\n",
      "Next points to be requested: \n",
      "[[5.59516738 1.20969665]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  28\n",
      "Run Time:  0.4757382869720459      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05578856358301263\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661819\n",
      "differential_evolution step 2: f(x)= -0.66445\n",
      "variance optimization tolerance of changed to:  0.06644500459074985\n",
      "Next points to be requested: \n",
      "[[8.91859255 2.75409009]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  29\n",
      "Run Time:  0.5539214611053467      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644500459074985\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06651368217886382\n",
      "Next points to be requested: \n",
      "[[9.43048561 2.79353523]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  30\n",
      "Run Time:  0.564227819442749      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06651368217886382\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665604\n",
      "differential_evolution step 2: f(x)= -0.665604\n",
      "variance optimization tolerance of changed to:  0.06656043836668483\n",
      "Next points to be requested: \n",
      "[[9.37531062 2.60843942]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  31\n",
      "Run Time:  0.5921535491943359      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656043836668483\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06498338813942246\n",
      "Next points to be requested: \n",
      "[[7.66425249 0.30701223]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  32\n",
      "Run Time:  0.5999021530151367      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06498338813942246\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663429\n",
      "variance optimization tolerance of changed to:  0.06634290507205791\n",
      "Next points to be requested: \n",
      "[[9.22965602 0.10972715]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  33\n",
      "Run Time:  0.6195113658905029      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06634290507205791\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06442511184213241\n",
      "Next points to be requested: \n",
      "[[3.55059742 2.31487317]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  34\n",
      "Run Time:  0.6282896995544434      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06442511184213241\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663456\n",
      "differential_evolution step 2: f(x)= -0.663456\n",
      "variance optimization tolerance of changed to:  0.06634562047114238\n",
      "Next points to be requested: \n",
      "[[9.44548948 2.95369474]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  35\n",
      "Run Time:  0.6633358001708984      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06634562047114238\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0578229289333987\n",
      "Next points to be requested: \n",
      "[[6.05588264 1.16050144]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  36\n",
      "Run Time:  0.6704490184783936      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0578229289333987\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660927\n",
      "differential_evolution step 2: f(x)= -0.665672\n",
      "variance optimization tolerance of changed to:  0.06656719920805358\n",
      "Next points to be requested: \n",
      "[[9.62237108 2.46488878]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  37\n",
      "Run Time:  0.6958258152008057      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656719920805358\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06312569028294727\n",
      "Next points to be requested: \n",
      "[[8.06567798 8.06534718]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  38\n",
      "Run Time:  0.7044544219970703      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06312569028294727\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663322\n",
      "variance optimization tolerance of changed to:  0.06633217457452553\n",
      "Next points to be requested: \n",
      "[[8.22628925 2.6276577 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  39\n",
      "Run Time:  0.7223246097564697      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06633217457452553\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04725700282469111\n",
      "Next points to be requested: \n",
      "[[8.61798979 9.51548537]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  40\n",
      "Run Time:  0.7298269271850586      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.04725700282469111\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665833\n",
      "differential_evolution step 2: f(x)= -0.665833\n",
      "variance optimization tolerance of changed to:  0.06658325166399857\n",
      "Next points to be requested: \n",
      "[[9.51144582 2.66187226]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  41\n",
      "Run Time:  0.7577862739562988      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06658325166399857\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0642821108862668\n",
      "Next points to be requested: \n",
      "[[7.81829613 6.26522774]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  42\n",
      "Run Time:  0.7659151554107666      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0642821108862668\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665983\n",
      "differential_evolution step 2: f(x)= -0.665983\n",
      "variance optimization tolerance of changed to:  0.06659833504039525\n",
      "Next points to be requested: \n",
      "[[9.58366697 2.58828916]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  43\n",
      "Run Time:  0.7920444011688232      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06659833504039525\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0634933559628696\n",
      "Next points to be requested: \n",
      "[[1.95556734 5.90024269]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  44\n",
      "Run Time:  0.8009033203125      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0634933559628696\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665016\n",
      "differential_evolution step 2: f(x)= -0.665016\n",
      "variance optimization tolerance of changed to:  0.06650155794928296\n",
      "Next points to be requested: \n",
      "[[9.745472   0.12208431]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  45\n",
      "Run Time:  0.8282482624053955      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650155794928296\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06460967308722793\n",
      "Next points to be requested: \n",
      "[[3.76169075 3.10192608]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  46\n",
      "Run Time:  0.8422670364379883      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06460967308722793\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664226\n",
      "differential_evolution step 2: f(x)= -0.664226\n",
      "variance optimization tolerance of changed to:  0.06642259528541528\n",
      "Next points to be requested: \n",
      "[[9.98160558 2.97076841]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  47\n",
      "Run Time:  0.8674921989440918      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642259528541528\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06369123975053895\n",
      "Next points to be requested: \n",
      "[[2.759549  8.7567488]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  48\n",
      "Run Time:  0.8809351921081543      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06369123975053895\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665173\n",
      "differential_evolution step 2: f(x)= -0.665173\n",
      "variance optimization tolerance of changed to:  0.06651734733051419\n",
      "Next points to be requested: \n",
      "[[9.47407601 0.0531699 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  49\n",
      "Run Time:  0.9090292453765869      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06651734733051419\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06279574140450155\n",
      "Next points to be requested: \n",
      "[[3.16383205 5.52717469]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  50\n",
      "Run Time:  0.9181966781616211      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06279574140450155\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663805\n",
      "differential_evolution step 2: f(x)= -0.66413\n",
      "variance optimization tolerance of changed to:  0.06641302150972271\n",
      "Next points to be requested: \n",
      "[[9.93028461 2.19216867]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  51\n",
      "Run Time:  0.9452300071716309      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06641302150972271\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06193137219974263\n",
      "Next points to be requested: \n",
      "[[8.76391479 8.21154395]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  52\n",
      "Run Time:  0.955329418182373      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06193137219974263\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665767\n",
      "variance optimization tolerance of changed to:  0.06657666521147738\n",
      "Next points to be requested: \n",
      "[[9.45944001 2.61421789]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  53\n",
      "Run Time:  0.9756085872650146      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657666521147738\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06505570743474005\n",
      "Next points to be requested: \n",
      "[[8.73363276 6.17943524]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  54\n",
      "Run Time:  0.9830577373504639      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06505570743474005\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.66587\n",
      "variance optimization tolerance of changed to:  0.0665870492131512\n",
      "Next points to be requested: \n",
      "[[9.62212384 2.71980782]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  55\n",
      "Run Time:  1.0014142990112305      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0665870492131512\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06332907390028815\n",
      "Next points to be requested: \n",
      "[[ 1.30978175 10.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  56\n",
      "Run Time:  1.0112130641937256      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06332907390028815\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663971\n",
      "variance optimization tolerance of changed to:  0.066397060198624\n",
      "Next points to be requested: \n",
      "[[8.83800216 2.47779496]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  57\n",
      "Run Time:  1.0316927433013916      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.066397060198624\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05109476426796203\n",
      "Next points to be requested: \n",
      "[[4.69995072 7.09468278]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  58\n",
      "Run Time:  1.0407443046569824      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05109476426796203\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664638\n",
      "differential_evolution step 2: f(x)= -0.664652\n",
      "variance optimization tolerance of changed to:  0.06646519260775283\n",
      "Next points to be requested: \n",
      "[[9.35925642 2.40250777]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  59\n",
      "Run Time:  1.1214993000030518      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06646519260775283\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06557391721448573\n",
      "Next points to be requested: \n",
      "[[9.85730416 6.2895968 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  60\n",
      "Run Time:  1.1370375156402588      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06557391721448573\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.659824\n",
      "differential_evolution step 2: f(x)= -0.659824\n",
      "variance optimization tolerance of changed to:  0.06598239372092445\n",
      "Next points to be requested: \n",
      "[[6.61084635 2.77446444]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  61\n",
      "Run Time:  1.166931390762329      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06598239372092445\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06372681366026488\n",
      "Next points to be requested: \n",
      "[[9.32804501 7.98386514]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  62\n",
      "Run Time:  1.17498779296875      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06372681366026488\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661115\n",
      "differential_evolution step 2: f(x)= -0.665213\n",
      "variance optimization tolerance of changed to:  0.06652129131371749\n",
      "Next points to be requested: \n",
      "[[9.20495367 2.57099538]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  63\n",
      "Run Time:  1.2016634941101074      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06652129131371749\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06457501180788151\n",
      "Next points to be requested: \n",
      "[[4.35854902 2.30666007]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  64\n",
      "Run Time:  1.211474895477295      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06457501180788151\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664099\n",
      "variance optimization tolerance of changed to:  0.06640993987697096\n",
      "Next points to be requested: \n",
      "[[8.84310463 2.78945314]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  65\n",
      "Run Time:  1.2389602661132812      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06640993987697096\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06395072772825243\n",
      "Next points to be requested: \n",
      "[[3.2415384  3.19222241]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  66\n",
      "Run Time:  1.2515573501586914      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06395072772825243\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.657206\n",
      "variance optimization tolerance of changed to:  0.06572058535632128\n",
      "Next points to be requested: \n",
      "[[5.19295871 2.75498535]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  67\n",
      "Run Time:  1.2702827453613281      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06572058535632128\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06262485768677498\n",
      "Next points to be requested: \n",
      "[[4.29952548 7.96186133]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  68\n",
      "Run Time:  1.2781786918640137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06262485768677498\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661855\n",
      "variance optimization tolerance of changed to:  0.066185468874038\n",
      "Next points to be requested: \n",
      "[[7.64109736 2.77884503]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  69\n",
      "Run Time:  1.298583745956421      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.066185468874038\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06372603167353973\n",
      "Next points to be requested: \n",
      "[[9.31771229 3.60044531]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  70\n",
      "Run Time:  1.308004379272461      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06372603167353973\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664764\n",
      "variance optimization tolerance of changed to:  0.06647639231811335\n",
      "Next points to be requested: \n",
      "[[9.92426195 2.92274989]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  71\n",
      "Run Time:  1.3270373344421387      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06647639231811335\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.055082660057281276\n",
      "Next points to be requested: \n",
      "[[4.92516415 0.90432036]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  72\n",
      "Run Time:  1.337310791015625      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.055082660057281276\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662723\n",
      "variance optimization tolerance of changed to:  0.06627226008836329\n",
      "Next points to be requested: \n",
      "[[7.9173489  2.68215938]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  73\n",
      "Run Time:  1.360086441040039      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06627226008836329\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06419706560900572\n",
      "Next points to be requested: \n",
      "[[6.79832653 5.81686068]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  74\n",
      "Run Time:  1.3699615001678467      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06419706560900572\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665755\n",
      "differential_evolution step 2: f(x)= -0.665755\n",
      "variance optimization tolerance of changed to:  0.06657548967785844\n",
      "Next points to be requested: \n",
      "[[9.78253374 2.41734059]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  75\n",
      "Run Time:  1.3973329067230225      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657548967785844\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.056426494701346544\n",
      "Next points to be requested: \n",
      "[[5.4524133  9.13562608]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  76\n",
      "Run Time:  1.4081370830535889      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.056426494701346544\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665026\n",
      "differential_evolution step 2: f(x)= -0.666365\n",
      "variance optimization tolerance of changed to:  0.06663650638052653\n",
      "Next points to be requested: \n",
      "[[9.94313439 2.73321851]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  77\n",
      "Run Time:  1.4461233615875244      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06663650638052653\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06498222598650946\n",
      "Next points to be requested: \n",
      "[[4.71263168 3.06915908]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  78\n",
      "Run Time:  1.4678981304168701      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06498222598650946\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664944\n",
      "differential_evolution step 2: f(x)= -0.664944\n",
      "variance optimization tolerance of changed to:  0.06649444451697208\n",
      "Next points to be requested: \n",
      "[[9.65203292 2.86280587]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  79\n",
      "Run Time:  1.5155768394470215      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06649444451697208\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06634556346103526\n",
      "Next points to be requested: \n",
      "[[8.36140678 2.57655087]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  80\n",
      "Run Time:  1.5276150703430176      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06634556346103526\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662051\n",
      "differential_evolution step 2: f(x)= -0.666023\n",
      "variance optimization tolerance of changed to:  0.06660228539251116\n",
      "Next points to be requested: \n",
      "[[9.66626859 2.52870711]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  81\n",
      "Run Time:  1.5583441257476807      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06660228539251116\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0657201816782467\n",
      "Next points to be requested: \n",
      "[[9.17888892 1.95851212]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  82\n",
      "Run Time:  1.5687873363494873      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0657201816782467\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660048\n",
      "variance optimization tolerance of changed to:  0.06600476031196384\n",
      "Next points to be requested: \n",
      "[[6.80312255 2.79895588]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  83\n",
      "Run Time:  1.588219165802002      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06600476031196384\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.062284360030253255\n",
      "Next points to be requested: \n",
      "[[4.56573393 8.61078037]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  84\n",
      "Run Time:  1.5963914394378662      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.062284360030253255\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662827\n",
      "differential_evolution step 2: f(x)= -0.662827\n",
      "differential_evolution step 3: f(x)= -0.664329\n",
      "variance optimization tolerance of changed to:  0.06643293813088606\n",
      "Next points to be requested: \n",
      "[[8.71256284 2.65045293]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  85\n",
      "Run Time:  1.632768154144287      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06643293813088606\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05947426616750076\n",
      "Next points to be requested: \n",
      "[[5.41418127 6.49090972]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  86\n",
      "Run Time:  1.6419336795806885      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05947426616750076\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.664747\n",
      "differential_evolution step 2: f(x)= -0.665015\n",
      "variance optimization tolerance of changed to:  0.06650147517315981\n",
      "Next points to be requested: \n",
      "[[9.75359415 2.87365526]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  87\n",
      "Run Time:  1.6693074703216553      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650147517315981\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0651685471730094\n",
      "Next points to be requested: \n",
      "[[9.30648134 6.36931267]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  88\n",
      "Run Time:  1.6769235134124756      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0651685471730094\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665086\n",
      "variance optimization tolerance of changed to:  0.06650863994476233\n",
      "Next points to be requested: \n",
      "[[9.28023151 2.49568505]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  89\n",
      "Run Time:  1.6960604190826416      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650863994476233\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05387044219029999\n",
      "Next points to be requested: \n",
      "[[3.94972772 0.68509712]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  90\n",
      "Run Time:  1.7064321041107178      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05387044219029999\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665881\n",
      "differential_evolution step 2: f(x)= -0.665881\n",
      "differential_evolution step 3: f(x)= -0.665881\n",
      "variance optimization tolerance of changed to:  0.06658811827175631\n",
      "Next points to be requested: \n",
      "[[9.99806627 2.3615742 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  91\n",
      "Run Time:  1.7398719787597656      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06658811827175631\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.059868771897546774\n",
      "Next points to be requested: \n",
      "[[6.62465411 7.15451271]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  92\n",
      "Run Time:  1.7488360404968262      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.059868771897546774\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663593\n",
      "differential_evolution step 2: f(x)= -0.666532\n",
      "variance optimization tolerance of changed to:  0.06665316034120797\n",
      "Next points to be requested: \n",
      "[[9.90368919 2.65968445]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  93\n",
      "Run Time:  1.7751493453979492      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665316034120797\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05301225473605417\n",
      "Next points to be requested: \n",
      "[[0.73521445 6.62437801]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  94\n",
      "Run Time:  1.7866766452789307      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05301225473605417\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662001\n",
      "differential_evolution step 2: f(x)= -0.66392\n",
      "variance optimization tolerance of changed to:  0.06639204564869815\n",
      "Next points to be requested: \n",
      "[[8.57173884 2.57927743]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  95\n",
      "Run Time:  1.8145148754119873      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06639204564869815\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06216237997415838\n",
      "Next points to be requested: \n",
      "[[5.79488506 8.3864241 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  96\n",
      "Run Time:  1.8238089084625244      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06216237997415838\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665789\n",
      "differential_evolution step 2: f(x)= -0.665789\n",
      "variance optimization tolerance of changed to:  0.06657894266682074\n",
      "Next points to be requested: \n",
      "[[9.47421171 2.63972007]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  97\n",
      "Run Time:  1.849839687347412      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657894266682074\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06311334959954433\n",
      "Next points to be requested: \n",
      "[[4.89315628 5.60229802]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  98\n",
      "Run Time:  1.858112096786499      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06311334959954433\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.6644\n",
      "variance optimization tolerance of changed to:  0.066439987480006\n",
      "Next points to be requested: \n",
      "[[8.89279567 2.5281399 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  99\n",
      "Run Time:  1.8803253173828125      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.066439987480006\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06205372201890699\n",
      "Next points to be requested: \n",
      "[[4.47032257 1.99731332]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  100\n",
      "Run Time:  1.888942003250122      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06205372201890699\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662363\n",
      "differential_evolution step 2: f(x)= -0.664334\n",
      "variance optimization tolerance of changed to:  0.0664334431076175\n",
      "Next points to be requested: \n",
      "[[8.83875849 2.74750123]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  101\n",
      "Run Time:  1.9177906513214111      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0664334431076175\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06414763470567866\n",
      "Next points to be requested: \n",
      "[[0.48885453 5.6679272 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  102\n",
      "Run Time:  1.9317312240600586      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06414763470567866\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664475\n",
      "differential_evolution step 2: f(x)= -0.664475\n",
      "variance optimization tolerance of changed to:  0.06644748998044829\n",
      "Next points to be requested: \n",
      "[[8.78633883 2.64764147]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  103\n",
      "Run Time:  1.9581880569458008      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644748998044829\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06468545864993115\n",
      "Next points to be requested: \n",
      "[[1.48641829 8.4670777 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  104\n",
      "Run Time:  1.9664762020111084      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06468545864993115\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664519\n",
      "variance optimization tolerance of changed to:  0.06645191010299234\n",
      "Next points to be requested: \n",
      "[[9.25233914 2.83168554]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  105\n",
      "Run Time:  1.9886457920074463      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06645191010299234\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06322017820736535\n",
      "Next points to be requested: \n",
      "[[6.99719384 7.72594145]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  106\n",
      "Run Time:  2.002408027648926      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06322017820736535\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663295\n",
      "differential_evolution step 2: f(x)= -0.664782\n",
      "variance optimization tolerance of changed to:  0.06647822727553665\n",
      "Next points to be requested: \n",
      "[[8.98476923 2.57799247]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  107\n",
      "Run Time:  2.060253143310547      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06647822727553665\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05564707083690532\n",
      "Next points to be requested: \n",
      "[[5.00259589 9.28562213]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  108\n",
      "Run Time:  2.0799832344055176      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05564707083690532\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.66379\n",
      "differential_evolution step 2: f(x)= -0.666366\n",
      "variance optimization tolerance of changed to:  0.06663658503751185\n",
      "Next points to be requested: \n",
      "[[9.91396814 2.48370745]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  109\n",
      "Run Time:  2.1196117401123047      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06663658503751185\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.061740005182747054\n",
      "Next points to be requested: \n",
      "[[6.85761715 1.60918306]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  110\n",
      "Run Time:  2.1330502033233643      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.061740005182747054\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665239\n",
      "variance optimization tolerance of changed to:  0.06652388526732311\n",
      "Next points to be requested: \n",
      "[[9.18862883 2.60351279]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  111\n",
      "Run Time:  2.156301498413086      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06652388526732311\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06119684294279724\n",
      "Next points to be requested: \n",
      "[[4.25305374 0.28293822]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  112\n",
      "Run Time:  2.164879083633423      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06119684294279724\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661586\n",
      "differential_evolution step 2: f(x)= -0.665121\n",
      "differential_evolution step 3: f(x)= -0.666932\n",
      "variance optimization tolerance of changed to:  0.0666931842910344\n",
      "Next points to be requested: \n",
      "[[9.85285136e+00 4.12482034e-03]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  113\n",
      "Run Time:  2.2027578353881836      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0666931842910344\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.062357896235097215\n",
      "Next points to be requested: \n",
      "[[4.4001923  2.02831934]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  114\n",
      "Run Time:  2.213435411453247      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.062357896235097215\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665655\n",
      "differential_evolution step 2: f(x)= -0.666495\n",
      "variance optimization tolerance of changed to:  0.06664953219950354\n",
      "Next points to be requested: \n",
      "[[9.86427111 2.63721964]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  115\n",
      "Run Time:  2.2456488609313965      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06664953219950354\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06316737345196341\n",
      "Next points to be requested: \n",
      "[[0.79409197 6.03193909]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  116\n",
      "Run Time:  2.254478931427002      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06316737345196341\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.66507\n",
      "differential_evolution step 2: f(x)= -0.66507\n",
      "variance optimization tolerance of changed to:  0.06650700293488024\n",
      "Next points to be requested: \n",
      "[[9.23582438 2.51216038]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  117\n",
      "Run Time:  2.2841737270355225      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650700293488024\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06228705797350888\n",
      "Next points to be requested: \n",
      "[[5.31883027 7.80560131]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  118\n",
      "Run Time:  2.293611526489258      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06228705797350888\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665904\n",
      "differential_evolution step 2: f(x)= -0.665904\n",
      "variance optimization tolerance of changed to:  0.06659040843433192\n",
      "Next points to be requested: \n",
      "[[9.53249457 2.61900029]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  119\n",
      "Run Time:  2.3231866359710693      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06659040843433192\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06412340053288997\n",
      "Next points to be requested: \n",
      "[[8.53587121 7.77924111]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  120\n",
      "Run Time:  2.33457350730896      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06412340053288997\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662003\n",
      "differential_evolution step 2: f(x)= -0.665329\n",
      "variance optimization tolerance of changed to:  0.0665328814922906\n",
      "Next points to be requested: \n",
      "[[9.30513381 2.71390899]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  121\n",
      "Run Time:  2.3698723316192627      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0665328814922906\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05985737842769297\n",
      "Next points to be requested: \n",
      "[[0.0907966  6.38154942]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  122\n",
      "Run Time:  2.379931926727295      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05985737842769297\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666532\n",
      "differential_evolution step 2: f(x)= -0.666532\n",
      "variance optimization tolerance of changed to:  0.0666532227167627\n",
      "Next points to be requested: \n",
      "[[9.91971802 2.67260568]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  123\n",
      "Run Time:  2.423827886581421      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0666532227167627\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06161996498246508\n",
      "Next points to be requested: \n",
      "[[7.96543178 5.36112324]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  124\n",
      "Run Time:  2.464893102645874      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06161996498246508\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.664333\n",
      "differential_evolution step 2: f(x)= -0.66448\n",
      "variance optimization tolerance of changed to:  0.0664479737529823\n",
      "Next points to be requested: \n",
      "[[9.96398463 2.21452806]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  125\n",
      "Run Time:  2.506704568862915      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0664479737529823\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06440716050218326\n",
      "Next points to be requested: \n",
      "[[8.90436635 7.55002854]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  126\n",
      "Run Time:  2.5181386470794678      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06440716050218326\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.657841\n",
      "differential_evolution step 2: f(x)= -0.664608\n",
      "differential_evolution step 3: f(x)= -0.666452\n",
      "variance optimization tolerance of changed to:  0.06664515414956933\n",
      "Next points to be requested: \n",
      "[[9.83747672 2.58171301]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  127\n",
      "Run Time:  2.55167818069458      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06664515414956933\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06405092373025877\n",
      "Next points to be requested: \n",
      "[[2.81743328 8.41270253]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  128\n",
      "Run Time:  2.5606272220611572      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06405092373025877\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665247\n",
      "differential_evolution step 2: f(x)= -0.665247\n",
      "variance optimization tolerance of changed to:  0.0665247416472554\n",
      "Next points to be requested: \n",
      "[[9.19388668 2.66195653]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  129\n",
      "Run Time:  2.5899901390075684      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0665247416472554\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06342360924765666\n",
      "Next points to be requested: \n",
      "[[3.60924766 5.89637238]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  130\n",
      "Run Time:  2.603522300720215      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06342360924765666\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661228\n",
      "differential_evolution step 2: f(x)= -0.664465\n",
      "variance optimization tolerance of changed to:  0.06644653377254653\n",
      "Next points to be requested: \n",
      "[[9.47885966 0.10002415]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  131\n",
      "Run Time:  2.6372783184051514      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644653377254653\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06554952297647855\n",
      "Next points to be requested: \n",
      "[[5.37614068 2.5055016 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  132\n",
      "Run Time:  2.6458349227905273      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06554952297647855\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.659491\n",
      "differential_evolution step 2: f(x)= -0.659491\n",
      "variance optimization tolerance of changed to:  0.0659491062297075\n",
      "Next points to be requested: \n",
      "[[6.3457563  2.70862245]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  133\n",
      "Run Time:  2.6731116771698      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0659491062297075\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.062145762193290294\n",
      "Next points to be requested: \n",
      "[[1.74413041 0.05593426]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  134\n",
      "Run Time:  2.682474374771118      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.062145762193290294\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.665171\n",
      "differential_evolution step 2: f(x)= -0.665171\n",
      "variance optimization tolerance of changed to:  0.06651711385127916\n",
      "Next points to be requested: \n",
      "[[9.1875945 2.5683194]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  135\n",
      "Run Time:  2.710596799850464      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06651711385127916\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03846554620662063\n",
      "Next points to be requested: \n",
      "[[1.2691909  1.22430048]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  136\n",
      "Run Time:  2.7289798259735107      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.03846554620662063\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666172\n",
      "differential_evolution step 2: f(x)= -0.666172\n",
      "variance optimization tolerance of changed to:  0.06661717265191623\n",
      "Next points to be requested: \n",
      "[[9.77239614 2.70903124]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  137\n",
      "Run Time:  2.7600152492523193      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06661717265191623\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06366673013165007\n",
      "Next points to be requested: \n",
      "[[2.27390459 3.20372573]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  138\n",
      "Run Time:  2.7701046466827393      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06366673013165007\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666433\n",
      "differential_evolution step 2: f(x)= -0.666433\n",
      "variance optimization tolerance of changed to:  0.06664328617779183\n",
      "Next points to be requested: \n",
      "[[9.83836407 2.56420176]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  139\n",
      "Run Time:  2.798203468322754      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06664328617779183\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06309227815182603\n",
      "Next points to be requested: \n",
      "[[0.         6.09985759]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  140\n",
      "Run Time:  2.8083620071411133      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06309227815182603\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664183\n",
      "differential_evolution step 2: f(x)= -0.665415\n",
      "variance optimization tolerance of changed to:  0.06654153820281923\n",
      "Next points to be requested: \n",
      "[[9.63175364 2.41794698]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  141\n",
      "Run Time:  2.841219425201416      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06654153820281923\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0634730576481377\n",
      "Next points to be requested: \n",
      "[[7.16432857 7.85495011]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  142\n",
      "Run Time:  2.85713791847229      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0634730576481377\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660593\n",
      "differential_evolution step 2: f(x)= -0.663755\n",
      "variance optimization tolerance of changed to:  0.06637554169157767\n",
      "Next points to be requested: \n",
      "[[9.40039169 2.29898476]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  143\n",
      "Run Time:  2.898594856262207      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06637554169157767\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0614985758970291\n",
      "Next points to be requested: \n",
      "[[5.62951358 8.51594738]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  144\n",
      "Run Time:  2.9166102409362793      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0614985758970291\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666529\n",
      "differential_evolution step 2: f(x)= -0.666529\n",
      "variance optimization tolerance of changed to:  0.06665289749351577\n",
      "Next points to be requested: \n",
      "[[9.89135094 2.64832182]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  145\n",
      "Run Time:  2.973386287689209      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665289749351577\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06272470476397286\n",
      "Next points to be requested: \n",
      "[[5.25376034 3.4499397 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  146\n",
      "Run Time:  3.0158023834228516      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06272470476397286\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.654696\n",
      "differential_evolution step 2: f(x)= -0.665451\n",
      "variance optimization tolerance of changed to:  0.06654507422980903\n",
      "Next points to be requested: \n",
      "[[9.48404278 0.0367531 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  147\n",
      "Run Time:  3.0466129779815674      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06654507422980903\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06617506394471827\n",
      "Next points to be requested: \n",
      "[[8.03796985 2.45596042]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  148\n",
      "Run Time:  3.0565664768218994      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06617506394471827\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666604\n",
      "differential_evolution step 2: f(x)= -0.666604\n",
      "variance optimization tolerance of changed to:  0.06666039939059555\n",
      "Next points to be requested: \n",
      "[[9.94571015 2.65982371]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  149\n",
      "Run Time:  3.08486270904541      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06666039939059555\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06294178301476018\n",
      "Next points to be requested: \n",
      "[[0.22488461 0.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  150\n",
      "Run Time:  3.094684600830078      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06294178301476018\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.66164\n",
      "differential_evolution step 2: f(x)= -0.662618\n",
      "differential_evolution step 3: f(x)= -0.662868\n",
      "variance optimization tolerance of changed to:  0.0662868079258672\n",
      "Next points to be requested: \n",
      "[[8.81503686 2.36776214]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  151\n",
      "Run Time:  3.1410670280456543      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0662868079258672\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06471777639500977\n",
      "Next points to be requested: \n",
      "[[0.871978   9.03219188]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  152\n",
      "Run Time:  3.151252508163452      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06471777639500977\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661618\n",
      "variance optimization tolerance of changed to:  0.06616178197433868\n",
      "Next points to be requested: \n",
      "[[9.92772943 3.10849111]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  153\n",
      "Run Time:  3.1730034351348877      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06616178197433868\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06420119103584794\n",
      "Next points to be requested: \n",
      "[[8.82481329 1.35941269]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  154\n",
      "Run Time:  3.184849500656128      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06420119103584794\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665941\n",
      "variance optimization tolerance of changed to:  0.06659412772103081\n",
      "Next points to be requested: \n",
      "[[9.58719162 2.55774368]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  155\n",
      "Run Time:  3.2134058475494385      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06659412772103081\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06298256276950982\n",
      "Next points to be requested: \n",
      "[[2.25319007 0.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  156\n",
      "Run Time:  3.2251904010772705      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06298256276950982\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665406\n",
      "variance optimization tolerance of changed to:  0.06654062456708475\n",
      "Next points to be requested: \n",
      "[[9.5811689  2.79290448]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  157\n",
      "Run Time:  3.2820370197296143      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06654062456708475\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05916580965004739\n",
      "Next points to be requested: \n",
      "[[4.18647051 3.6543641 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  158\n",
      "Run Time:  3.295301914215088      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05916580965004739\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 2: f(x)= -0.665666\n",
      "variance optimization tolerance of changed to:  0.06656656246568902\n",
      "Next points to be requested: \n",
      "[[9.42354786 2.58066438]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  159\n",
      "Run Time:  3.3241400718688965      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656656246568902\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06027396178335566\n",
      "Next points to be requested: \n",
      "[[4.1682303  0.34192972]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  160\n",
      "Run Time:  3.339287281036377      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06027396178335566\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666593\n",
      "differential_evolution step 2: f(x)= -0.666593\n",
      "variance optimization tolerance of changed to:  0.0666593406596873\n",
      "Next points to be requested: \n",
      "[[9.9139424  2.58393712]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  161\n",
      "Run Time:  3.404175281524658      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0666593406596873\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0652739516390598\n",
      "Next points to be requested: \n",
      "[[5.1930171  3.01841156]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  162\n",
      "Run Time:  3.4156973361968994      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0652739516390598\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665714\n",
      "differential_evolution step 2: f(x)= -0.665714\n",
      "variance optimization tolerance of changed to:  0.06657144305342824\n",
      "Next points to be requested: \n",
      "[[9.9027665  0.10754123]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  163\n",
      "Run Time:  3.4527361392974854      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657144305342824\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06376929368115063\n",
      "Next points to be requested: \n",
      "[[0.55309062 5.5270606 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  164\n",
      "Run Time:  3.463932514190674      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06376929368115063\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666268\n",
      "differential_evolution step 2: f(x)= -0.666268\n",
      "variance optimization tolerance of changed to:  0.06662677767871049\n",
      "Next points to be requested: \n",
      "[[9.8286185  2.70922255]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  165\n",
      "Run Time:  3.4965341091156006      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06662677767871049\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06350306558655026\n",
      "Next points to be requested: \n",
      "[[1.23355859 8.12843318]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  166\n",
      "Run Time:  3.5152368545532227      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06350306558655026\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.665462\n",
      "differential_evolution step 2: f(x)= -0.666501\n",
      "variance optimization tolerance of changed to:  0.06665009027397903\n",
      "Next points to be requested: \n",
      "[[9.71429057e+00 9.03109455e-03]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  167\n",
      "Run Time:  3.5534615516662598      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665009027397903\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06226282632089933\n",
      "Next points to be requested: \n",
      "[[6.6571595  8.26887649]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  168\n",
      "Run Time:  3.5641939640045166      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06226282632089933\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665718\n",
      "variance optimization tolerance of changed to:  0.06657175234410927\n",
      "Next points to be requested: \n",
      "[[9.52910053 2.519981  ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  169\n",
      "Run Time:  3.587847948074341      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657175234410927\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.060888749159751336\n",
      "Next points to be requested: \n",
      "[[0.56243804 6.27813109]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  170\n",
      "Run Time:  3.5990793704986572      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.060888749159751336\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664731\n",
      "differential_evolution step 2: f(x)= -0.664731\n",
      "differential_evolution step 3: f(x)= -0.664731\n",
      "variance optimization tolerance of changed to:  0.06647312555524544\n",
      "Next points to be requested: \n",
      "[[9.45698394 2.84888826]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  171\n",
      "Run Time:  3.63655424118042      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06647312555524544\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06621170150969972\n",
      "Next points to be requested: \n",
      "[[8.87177904 0.10657312]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  172\n",
      "Run Time:  3.6474738121032715      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06621170150969972\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665821\n",
      "differential_evolution step 2: f(x)= -0.665821\n",
      "variance optimization tolerance of changed to:  0.06658211597507267\n",
      "Next points to be requested: \n",
      "[[9.49017174 2.63601719]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  173\n",
      "Run Time:  3.682194948196411      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06658211597507267\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06446146250709997\n",
      "Next points to be requested: \n",
      "[[0.89956019 9.14759144]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  174\n",
      "Run Time:  3.6925182342529297      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06446146250709997\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663307\n",
      "differential_evolution step 2: f(x)= -0.663307\n",
      "variance optimization tolerance of changed to:  0.0663306661398554\n",
      "Next points to be requested: \n",
      "[[8.28700653 2.5798397 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  175\n",
      "Run Time:  3.7265429496765137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0663306661398554\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06280865470679407\n",
      "Next points to be requested: \n",
      "[[1.61923112 6.04362053]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  176\n",
      "Run Time:  3.7383525371551514      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06280865470679407\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664244\n",
      "differential_evolution step 2: f(x)= -0.664244\n",
      "variance optimization tolerance of changed to:  0.06642444409705545\n",
      "Next points to be requested: \n",
      "[[8.68422891 2.68459389]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  177\n",
      "Run Time:  3.767888069152832      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642444409705545\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0628051984370351\n",
      "Next points to be requested: \n",
      "[[1.42303725 0.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  178\n",
      "Run Time:  3.779985189437866      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0628051984370351\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666778\n",
      "differential_evolution step 2: f(x)= -0.666778\n",
      "differential_evolution step 3: f(x)= -0.666778\n",
      "variance optimization tolerance of changed to:  0.06667779788121568\n",
      "Next points to be requested: \n",
      "[[9.92861431 0.03197068]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  179\n",
      "Run Time:  3.817293643951416      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06667779788121568\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06342723922587504\n",
      "Next points to be requested: \n",
      "[[0.64366813 5.99844417]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  180\n",
      "Run Time:  3.8264713287353516      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06342723922587504\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663935\n",
      "differential_evolution step 2: f(x)= -0.665232\n",
      "variance optimization tolerance of changed to:  0.06652323465157206\n",
      "Next points to be requested: \n",
      "[[9.38704355 2.76638554]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  181\n",
      "Run Time:  3.855900526046753      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06652323465157206\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0626767888277225\n",
      "Next points to be requested: \n",
      "[[3.19655022 8.01576706]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  182\n",
      "Run Time:  3.867997407913208      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0626767888277225\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663443\n",
      "differential_evolution step 2: f(x)= -0.665567\n",
      "variance optimization tolerance of changed to:  0.06655672242975509\n",
      "Next points to be requested: \n",
      "[[9.38003248 2.57334178]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  183\n",
      "Run Time:  3.92969012260437      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06655672242975509\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance optimization tolerance of changed to:  0.06236490341470984\n",
      "Next points to be requested: \n",
      "[[5.78260577 8.35148309]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  184\n",
      "Run Time:  3.9569475650787354      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06236490341470984\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664684\n",
      "differential_evolution step 2: f(x)= -0.664684\n",
      "differential_evolution step 3: f(x)= -0.666569\n",
      "variance optimization tolerance of changed to:  0.06665694935290058\n",
      "Next points to be requested: \n",
      "[[9.89668907 2.60629343]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  185\n",
      "Run Time:  3.9924557209014893      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665694935290058\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06048334632261292\n",
      "Next points to be requested: \n",
      "[[3.69889552 3.53881735]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  186\n",
      "Run Time:  4.008392572402954      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06048334632261292\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660634\n",
      "differential_evolution step 2: f(x)= -0.663608\n",
      "variance optimization tolerance of changed to:  0.06636082049711355\n",
      "Next points to be requested: \n",
      "[[9.57759961 0.17609204]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  187\n",
      "Run Time:  4.037184953689575      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06636082049711355\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06484367370026344\n",
      "Next points to be requested: \n",
      "[[2.59574216 3.00859216]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  188\n",
      "Run Time:  4.048826217651367      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06484367370026344\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664434\n",
      "variance optimization tolerance of changed to:  0.06644342233914087\n",
      "Next points to be requested: \n",
      "[[9.10186903 0.02526848]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  189\n",
      "Run Time:  4.071019411087036      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644342233914087\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06287141664318849\n",
      "Next points to be requested: \n",
      "[[2.19007639 8.05457544]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  190\n",
      "Run Time:  4.08373761177063      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06287141664318849\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664388\n",
      "differential_evolution step 2: f(x)= -0.664388\n",
      "variance optimization tolerance of changed to:  0.06643884127765903\n",
      "Next points to be requested: \n",
      "[[8.76036682 2.60755183]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  191\n",
      "Run Time:  4.11801815032959      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06643884127765903\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05736630566879134\n",
      "Next points to be requested: \n",
      "[[5.65421317 0.96594324]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  192\n",
      "Run Time:  4.129374980926514      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05736630566879134\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.665881\n",
      "differential_evolution step 2: f(x)= -0.666289\n",
      "differential_evolution step 3: f(x)= -0.666289\n",
      "variance optimization tolerance of changed to:  0.06662891484381699\n",
      "Next points to be requested: \n",
      "[[9.77243647 2.66671667]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  193\n",
      "Run Time:  4.170217752456665      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06662891484381699\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06397836343694828\n",
      "Next points to be requested: \n",
      "[[9.64360267 7.95015297]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  194\n",
      "Run Time:  4.185134172439575      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06397836343694828\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666163\n",
      "differential_evolution step 2: f(x)= -0.666163\n",
      "variance optimization tolerance of changed to:  0.06661633677162924\n",
      "Next points to be requested: \n",
      "[[9.68607552 2.57660405]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  195\n",
      "Run Time:  4.213635683059692      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06661633677162924\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06508370016424876\n",
      "Next points to be requested: \n",
      "[[3.70833096 2.45597592]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  196\n",
      "Run Time:  4.223982810974121      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06508370016424876\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664279\n",
      "differential_evolution step 2: f(x)= -0.664279\n",
      "variance optimization tolerance of changed to:  0.06642790965540944\n",
      "Next points to be requested: \n",
      "[[9.47683326 2.89531618]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  197\n",
      "Run Time:  4.25578236579895      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642790965540944\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06389931253011626\n",
      "Next points to be requested: \n",
      "[[1.06493576 5.83039207]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  198\n",
      "Run Time:  4.284764051437378      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06389931253011626\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662809\n",
      "differential_evolution step 2: f(x)= -0.663584\n",
      "variance optimization tolerance of changed to:  0.06635836919474646\n",
      "Next points to be requested: \n",
      "[[9.15066976 2.90271859]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  199\n",
      "Run Time:  4.340045928955078      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06635836919474646\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05750263864169297\n",
      "Next points to be requested: \n",
      "[[5.73673197 8.94734515]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "====================================================\n",
      "The autonomous experiment was concluded successfully\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "#/usr/bin/env python\n",
    "import numpy as np\n",
    "from gpcam.autonomous_experimenter import AutonomousExperimenterfvGP\n",
    "\n",
    "def instrument(data):\n",
    "    for entry in data:\n",
    "        entry[\"value\"] = np.array([np.sin(np.linalg.norm(entry[\"position\"])),np.sin(np.linalg.norm(entry[\"position\"]))])\n",
    "    return data\n",
    "\n",
    "my_fvae = AutonomousExperimenterfvGP(np.array([[0,10],[0,10]]),2,1,\n",
    "                                     instrument,np.ones((3)),np.array([[0.001,100],[0.001,100],[0.001,100]]),\n",
    "                                     init_dataset_size= 10)\n",
    "my_fvae.train()\n",
    "input(\"training done\")\n",
    "my_ae.go(N = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surgical-recording",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-secretary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
