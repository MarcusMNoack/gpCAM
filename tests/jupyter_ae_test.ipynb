{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tracked-aberdeen",
   "metadata": {},
   "source": [
    "## Single-Task GP AE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "auburn-desert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n",
      "\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "GP successfully initiated\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-567b06517d95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m my_ae = AutonomousExperimenterGP(np.array([[0,10],[0,10]]),instrument,\n\u001b[0m\u001b[1;32m     11\u001b[0m                                  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                  init_dataset_size= 10)\n",
      "\u001b[0;32m~/Coding/Professional/gpCAM/gpcam/autonomous_experimenter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parameter_bounds, instrument_func, hyperparameters, hyperparameter_bounds, init_dataset_size, acq_func, cost_func, cost_update_func, cost_func_params, kernel_func, prior_mean_func, run_every_iteration, x, y, v, dataset, append_data, compute_device, sparse, training_dask_client, acq_func_opt_dask_client)\u001b[0m\n\u001b[1;32m    105\u001b[0m             sparse = self.sparse)\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m#init costs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_costs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost_func_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"##################################################################################\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "#/usr/bin/env python\n",
    "import numpy as np\n",
    "from gpcam.autonomous_experimenter import AutonomousExperimenterGP\n",
    "\n",
    "def instrument(data):\n",
    "    for entry in data:\n",
    "        entry[\"value\"] = np.sin(np.linalg.norm(entry[\"position\"]))\n",
    "    return data\n",
    "\n",
    "my_ae = AutonomousExperimenterGP(np.array([[0,10],[0,10]]),instrument,\n",
    "                                 np.ones((3)),np.array([[0.001,100],[0.001,100],[0.001,100]]),\n",
    "                                 init_dataset_size= 10)\n",
    "my_ae.train()\n",
    "input(\"training done\")\n",
    "my_ae.go(N = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-motion",
   "metadata": {},
   "source": [
    "## Multi-Task GP AE Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "representative-calculation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAUTION: you have not provided data variances, they will set to be 1 percent of the data values!\n",
      "Costs successfully initialized\n",
      "##################################################################################\n",
      "Initialization successfully concluded\n",
      "now train(...) or train_async(...), and then go(...)\n",
      "##################################################################################\n",
      "GP training started with  20  data points\n",
      "Hyper-parameter tuning in progress. Old hyper-parameters:  [1. 1. 1.]  with old log likelihood:  nan\n",
      "method:  global\n",
      "I am performing a global differential evolution algorithm to find the optimal hyperparameters.\n",
      "maximum number of iterations:  20\n",
      "termination tolerance:  1e-06\n",
      "bounds:  [[1.e-03 1.e+02]\n",
      " [1.e-03 1.e+02]\n",
      " [1.e-03 1.e+02]]\n",
      "differential_evolution step 1: f(x)= nan\n",
      "differential_evolution step 2: f(x)= nan\n",
      "differential_evolution step 3: f(x)= nan\n",
      "differential_evolution step 4: f(x)= nan\n",
      "differential_evolution step 5: f(x)= nan\n",
      "differential_evolution step 6: f(x)= nan\n",
      "differential_evolution step 7: f(x)= nan\n",
      "differential_evolution step 8: f(x)= nan\n",
      "differential_evolution step 9: f(x)= nan\n",
      "differential_evolution step 10: f(x)= nan\n",
      "differential_evolution step 11: f(x)= nan\n",
      "differential_evolution step 12: f(x)= nan\n",
      "differential_evolution step 13: f(x)= nan\n",
      "differential_evolution step 14: f(x)= nan\n",
      "differential_evolution step 15: f(x)= nan\n",
      "differential_evolution step 16: f(x)= nan\n",
      "differential_evolution step 17: f(x)= nan\n",
      "differential_evolution step 18: f(x)= nan\n",
      "differential_evolution step 19: f(x)= nan\n",
      "differential_evolution step 20: f(x)= nan\n",
      "I found hyper-parameters  [ 4.58490202 71.11226116 66.9284315 ]  with likelihood  nan  via global optimization\n",
      "training done\n",
      "Date and time:        2021-05-17_15_11_08\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  10\n",
      "Run Time:  0.0004107952117919922      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  1e-06\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666949\n",
      "differential_evolution step 2: f(x)= -0.666949\n",
      "differential_evolution step 3: f(x)= -0.666949\n",
      "differential_evolution step 4: f(x)= -0.666949\n",
      "differential_evolution step 5: f(x)= -0.666949\n",
      "differential_evolution step 6: f(x)= -0.666949\n",
      "differential_evolution step 7: f(x)= -0.666949\n",
      "differential_evolution step 8: f(x)= -0.666949\n",
      "differential_evolution step 9: f(x)= -0.666949\n",
      "differential_evolution step 10: f(x)= -0.666949\n",
      "differential_evolution step 11: f(x)= -0.666949\n",
      "differential_evolution step 12: f(x)= -0.666949\n",
      "differential_evolution step 13: f(x)= -0.666949\n",
      "differential_evolution step 14: f(x)= -0.667011\n",
      "differential_evolution step 15: f(x)= -0.667011\n",
      "differential_evolution step 16: f(x)= -0.667064\n",
      "differential_evolution step 17: f(x)= -0.667064\n",
      "differential_evolution step 18: f(x)= -0.667248\n",
      "differential_evolution step 19: f(x)= -0.667248\n",
      "differential_evolution step 20: f(x)= -0.667248\n",
      "variance optimization tolerance of changed to:  0.06672477504296123\n",
      "Next points to be requested: \n",
      "[[9.96385706e+00 1.45499768e-03]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  11\n",
      "Run Time:  0.18946552276611328      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06672477504296123\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06326788034067214\n",
      "Next points to be requested: \n",
      "[[5.03721849 3.37448214]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  12\n",
      "Run Time:  0.19803357124328613      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06326788034067214\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665317\n",
      "differential_evolution step 2: f(x)= -0.665317\n",
      "variance optimization tolerance of changed to:  0.06653173310939929\n",
      "Next points to be requested: \n",
      "[[9.44799596 2.46982538]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  13\n",
      "Run Time:  0.22661042213439941      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06653173310939929\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.063763393695835\n",
      "Next points to be requested: \n",
      "[[2.7193728  8.74242528]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  14\n",
      "Run Time:  0.23637962341308594      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.063763393695835\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663714\n",
      "variance optimization tolerance of changed to:  0.06637135656439169\n",
      "Next points to be requested: \n",
      "[[8.98314738 2.40425369]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  15\n",
      "Run Time:  0.25820112228393555      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06637135656439169\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.060281966852425\n",
      "Next points to be requested: \n",
      "[[6.02068589 7.41967909]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  16\n",
      "Run Time:  0.26535654067993164      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.060281966852425\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666212\n",
      "differential_evolution step 2: f(x)= -0.666212\n",
      "variance optimization tolerance of changed to:  0.06662122554586679\n",
      "Next points to be requested: \n",
      "[[9.90947893 2.45032126]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  17\n",
      "Run Time:  0.2960629463195801      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06662122554586679\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.061783119993249584\n",
      "Next points to be requested: \n",
      "[[6.11569815 7.59470084]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  18\n",
      "Run Time:  0.3042111396789551      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.061783119993249584\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663317\n",
      "differential_evolution step 2: f(x)= -0.664177\n",
      "variance optimization tolerance of changed to:  0.06641769627759592\n",
      "Next points to be requested: \n",
      "[[8.75345469 2.5455443 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  19\n",
      "Run Time:  0.32880663871765137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06641769627759592\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.060365713612159345\n",
      "Next points to be requested: \n",
      "[[5.35122785 1.77879114]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  20\n",
      "Run Time:  0.33699893951416016      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.060365713612159345\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666112\n",
      "differential_evolution step 2: f(x)= -0.666112\n",
      "differential_evolution step 3: f(x)= -0.666112\n",
      "variance optimization tolerance of changed to:  0.06661120651073982\n",
      "Next points to be requested: \n",
      "[[9.94243593 0.08657951]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  21\n",
      "Run Time:  0.3721926212310791      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06661120651073982\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06169077304992319\n",
      "Next points to be requested: \n",
      "[[8.42458318 8.24078567]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  22\n",
      "Run Time:  0.38024473190307617      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06169077304992319\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663005\n",
      "variance optimization tolerance of changed to:  0.06630052151903129\n",
      "Next points to be requested: \n",
      "[[8.29247585 2.79703065]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  23\n",
      "Run Time:  0.399289608001709      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06630052151903129\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06594051913544112\n",
      "Next points to be requested: \n",
      "[[7.54994542 2.96388611]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  24\n",
      "Run Time:  0.4075009822845459      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06594051913544112\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.664867\n",
      "differential_evolution step 2: f(x)= -0.665637\n",
      "variance optimization tolerance of changed to:  0.06656368341489503\n",
      "Next points to be requested: \n",
      "[[9.39524063 2.60115416]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  25\n",
      "Run Time:  0.43551015853881836      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656368341489503\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06442513007643091\n",
      "Next points to be requested: \n",
      "[[6.66293562 2.06582047]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  26\n",
      "Run Time:  0.44260668754577637      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06442513007643091\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664265\n",
      "differential_evolution step 2: f(x)= -0.664265\n",
      "variance optimization tolerance of changed to:  0.06642650959780513\n",
      "Next points to be requested: \n",
      "[[8.93818836 2.48657745]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  27\n",
      "Run Time:  0.4687504768371582      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642650959780513\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05578856358301263\n",
      "Next points to be requested: \n",
      "[[5.59516738 1.20969665]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  28\n",
      "Run Time:  0.4757382869720459      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05578856358301263\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661819\n",
      "differential_evolution step 2: f(x)= -0.66445\n",
      "variance optimization tolerance of changed to:  0.06644500459074985\n",
      "Next points to be requested: \n",
      "[[8.91859255 2.75409009]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  29\n",
      "Run Time:  0.5539214611053467      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644500459074985\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06651368217886382\n",
      "Next points to be requested: \n",
      "[[9.43048561 2.79353523]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  30\n",
      "Run Time:  0.564227819442749      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06651368217886382\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665604\n",
      "differential_evolution step 2: f(x)= -0.665604\n",
      "variance optimization tolerance of changed to:  0.06656043836668483\n",
      "Next points to be requested: \n",
      "[[9.37531062 2.60843942]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  31\n",
      "Run Time:  0.5921535491943359      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656043836668483\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06498338813942246\n",
      "Next points to be requested: \n",
      "[[7.66425249 0.30701223]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  32\n",
      "Run Time:  0.5999021530151367      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06498338813942246\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663429\n",
      "variance optimization tolerance of changed to:  0.06634290507205791\n",
      "Next points to be requested: \n",
      "[[9.22965602 0.10972715]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  33\n",
      "Run Time:  0.6195113658905029      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06634290507205791\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06442511184213241\n",
      "Next points to be requested: \n",
      "[[3.55059742 2.31487317]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  34\n",
      "Run Time:  0.6282896995544434      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06442511184213241\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663456\n",
      "differential_evolution step 2: f(x)= -0.663456\n",
      "variance optimization tolerance of changed to:  0.06634562047114238\n",
      "Next points to be requested: \n",
      "[[9.44548948 2.95369474]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  35\n",
      "Run Time:  0.6633358001708984      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06634562047114238\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0578229289333987\n",
      "Next points to be requested: \n",
      "[[6.05588264 1.16050144]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  36\n",
      "Run Time:  0.6704490184783936      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0578229289333987\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660927\n",
      "differential_evolution step 2: f(x)= -0.665672\n",
      "variance optimization tolerance of changed to:  0.06656719920805358\n",
      "Next points to be requested: \n",
      "[[9.62237108 2.46488878]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  37\n",
      "Run Time:  0.6958258152008057      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656719920805358\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06312569028294727\n",
      "Next points to be requested: \n",
      "[[8.06567798 8.06534718]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  38\n",
      "Run Time:  0.7044544219970703      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06312569028294727\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663322\n",
      "variance optimization tolerance of changed to:  0.06633217457452553\n",
      "Next points to be requested: \n",
      "[[8.22628925 2.6276577 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  39\n",
      "Run Time:  0.7223246097564697      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06633217457452553\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.04725700282469111\n",
      "Next points to be requested: \n",
      "[[8.61798979 9.51548537]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  40\n",
      "Run Time:  0.7298269271850586      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.04725700282469111\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665833\n",
      "differential_evolution step 2: f(x)= -0.665833\n",
      "variance optimization tolerance of changed to:  0.06658325166399857\n",
      "Next points to be requested: \n",
      "[[9.51144582 2.66187226]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  41\n",
      "Run Time:  0.7577862739562988      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06658325166399857\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0642821108862668\n",
      "Next points to be requested: \n",
      "[[7.81829613 6.26522774]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  42\n",
      "Run Time:  0.7659151554107666      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0642821108862668\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665983\n",
      "differential_evolution step 2: f(x)= -0.665983\n",
      "variance optimization tolerance of changed to:  0.06659833504039525\n",
      "Next points to be requested: \n",
      "[[9.58366697 2.58828916]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  43\n",
      "Run Time:  0.7920444011688232      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06659833504039525\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0634933559628696\n",
      "Next points to be requested: \n",
      "[[1.95556734 5.90024269]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  44\n",
      "Run Time:  0.8009033203125      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0634933559628696\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665016\n",
      "differential_evolution step 2: f(x)= -0.665016\n",
      "variance optimization tolerance of changed to:  0.06650155794928296\n",
      "Next points to be requested: \n",
      "[[9.745472   0.12208431]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  45\n",
      "Run Time:  0.8282482624053955      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650155794928296\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06460967308722793\n",
      "Next points to be requested: \n",
      "[[3.76169075 3.10192608]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  46\n",
      "Run Time:  0.8422670364379883      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06460967308722793\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664226\n",
      "differential_evolution step 2: f(x)= -0.664226\n",
      "variance optimization tolerance of changed to:  0.06642259528541528\n",
      "Next points to be requested: \n",
      "[[9.98160558 2.97076841]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  47\n",
      "Run Time:  0.8674921989440918      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642259528541528\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06369123975053895\n",
      "Next points to be requested: \n",
      "[[2.759549  8.7567488]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  48\n",
      "Run Time:  0.8809351921081543      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06369123975053895\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665173\n",
      "differential_evolution step 2: f(x)= -0.665173\n",
      "variance optimization tolerance of changed to:  0.06651734733051419\n",
      "Next points to be requested: \n",
      "[[9.47407601 0.0531699 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  49\n",
      "Run Time:  0.9090292453765869      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06651734733051419\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06279574140450155\n",
      "Next points to be requested: \n",
      "[[3.16383205 5.52717469]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  50\n",
      "Run Time:  0.9181966781616211      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06279574140450155\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663805\n",
      "differential_evolution step 2: f(x)= -0.66413\n",
      "variance optimization tolerance of changed to:  0.06641302150972271\n",
      "Next points to be requested: \n",
      "[[9.93028461 2.19216867]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  51\n",
      "Run Time:  0.9452300071716309      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06641302150972271\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06193137219974263\n",
      "Next points to be requested: \n",
      "[[8.76391479 8.21154395]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  52\n",
      "Run Time:  0.955329418182373      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06193137219974263\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665767\n",
      "variance optimization tolerance of changed to:  0.06657666521147738\n",
      "Next points to be requested: \n",
      "[[9.45944001 2.61421789]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  53\n",
      "Run Time:  0.9756085872650146      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657666521147738\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06505570743474005\n",
      "Next points to be requested: \n",
      "[[8.73363276 6.17943524]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  54\n",
      "Run Time:  0.9830577373504639      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06505570743474005\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.66587\n",
      "variance optimization tolerance of changed to:  0.0665870492131512\n",
      "Next points to be requested: \n",
      "[[9.62212384 2.71980782]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  55\n",
      "Run Time:  1.0014142990112305      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0665870492131512\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06332907390028815\n",
      "Next points to be requested: \n",
      "[[ 1.30978175 10.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  56\n",
      "Run Time:  1.0112130641937256      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06332907390028815\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663971\n",
      "variance optimization tolerance of changed to:  0.066397060198624\n",
      "Next points to be requested: \n",
      "[[8.83800216 2.47779496]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  57\n",
      "Run Time:  1.0316927433013916      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.066397060198624\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05109476426796203\n",
      "Next points to be requested: \n",
      "[[4.69995072 7.09468278]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  58\n",
      "Run Time:  1.0407443046569824      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05109476426796203\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664638\n",
      "differential_evolution step 2: f(x)= -0.664652\n",
      "variance optimization tolerance of changed to:  0.06646519260775283\n",
      "Next points to be requested: \n",
      "[[9.35925642 2.40250777]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  59\n",
      "Run Time:  1.1214993000030518      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06646519260775283\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06557391721448573\n",
      "Next points to be requested: \n",
      "[[9.85730416 6.2895968 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  60\n",
      "Run Time:  1.1370375156402588      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06557391721448573\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.659824\n",
      "differential_evolution step 2: f(x)= -0.659824\n",
      "variance optimization tolerance of changed to:  0.06598239372092445\n",
      "Next points to be requested: \n",
      "[[6.61084635 2.77446444]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  61\n",
      "Run Time:  1.166931390762329      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06598239372092445\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06372681366026488\n",
      "Next points to be requested: \n",
      "[[9.32804501 7.98386514]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  62\n",
      "Run Time:  1.17498779296875      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06372681366026488\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661115\n",
      "differential_evolution step 2: f(x)= -0.665213\n",
      "variance optimization tolerance of changed to:  0.06652129131371749\n",
      "Next points to be requested: \n",
      "[[9.20495367 2.57099538]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  63\n",
      "Run Time:  1.2016634941101074      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06652129131371749\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06457501180788151\n",
      "Next points to be requested: \n",
      "[[4.35854902 2.30666007]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  64\n",
      "Run Time:  1.211474895477295      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06457501180788151\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664099\n",
      "variance optimization tolerance of changed to:  0.06640993987697096\n",
      "Next points to be requested: \n",
      "[[8.84310463 2.78945314]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  65\n",
      "Run Time:  1.2389602661132812      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06640993987697096\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06395072772825243\n",
      "Next points to be requested: \n",
      "[[3.2415384  3.19222241]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  66\n",
      "Run Time:  1.2515573501586914      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06395072772825243\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.657206\n",
      "variance optimization tolerance of changed to:  0.06572058535632128\n",
      "Next points to be requested: \n",
      "[[5.19295871 2.75498535]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  67\n",
      "Run Time:  1.2702827453613281      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06572058535632128\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06262485768677498\n",
      "Next points to be requested: \n",
      "[[4.29952548 7.96186133]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  68\n",
      "Run Time:  1.2781786918640137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06262485768677498\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661855\n",
      "variance optimization tolerance of changed to:  0.066185468874038\n",
      "Next points to be requested: \n",
      "[[7.64109736 2.77884503]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  69\n",
      "Run Time:  1.298583745956421      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.066185468874038\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06372603167353973\n",
      "Next points to be requested: \n",
      "[[9.31771229 3.60044531]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  70\n",
      "Run Time:  1.308004379272461      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06372603167353973\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664764\n",
      "variance optimization tolerance of changed to:  0.06647639231811335\n",
      "Next points to be requested: \n",
      "[[9.92426195 2.92274989]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  71\n",
      "Run Time:  1.3270373344421387      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06647639231811335\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.055082660057281276\n",
      "Next points to be requested: \n",
      "[[4.92516415 0.90432036]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  72\n",
      "Run Time:  1.337310791015625      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.055082660057281276\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662723\n",
      "variance optimization tolerance of changed to:  0.06627226008836329\n",
      "Next points to be requested: \n",
      "[[7.9173489  2.68215938]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  73\n",
      "Run Time:  1.360086441040039      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06627226008836329\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06419706560900572\n",
      "Next points to be requested: \n",
      "[[6.79832653 5.81686068]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  74\n",
      "Run Time:  1.3699615001678467      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06419706560900572\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665755\n",
      "differential_evolution step 2: f(x)= -0.665755\n",
      "variance optimization tolerance of changed to:  0.06657548967785844\n",
      "Next points to be requested: \n",
      "[[9.78253374 2.41734059]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  75\n",
      "Run Time:  1.3973329067230225      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657548967785844\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.056426494701346544\n",
      "Next points to be requested: \n",
      "[[5.4524133  9.13562608]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  76\n",
      "Run Time:  1.4081370830535889      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.056426494701346544\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665026\n",
      "differential_evolution step 2: f(x)= -0.666365\n",
      "variance optimization tolerance of changed to:  0.06663650638052653\n",
      "Next points to be requested: \n",
      "[[9.94313439 2.73321851]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  77\n",
      "Run Time:  1.4461233615875244      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06663650638052653\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06498222598650946\n",
      "Next points to be requested: \n",
      "[[4.71263168 3.06915908]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  78\n",
      "Run Time:  1.4678981304168701      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06498222598650946\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664944\n",
      "differential_evolution step 2: f(x)= -0.664944\n",
      "variance optimization tolerance of changed to:  0.06649444451697208\n",
      "Next points to be requested: \n",
      "[[9.65203292 2.86280587]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  79\n",
      "Run Time:  1.5155768394470215      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06649444451697208\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06634556346103526\n",
      "Next points to be requested: \n",
      "[[8.36140678 2.57655087]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  80\n",
      "Run Time:  1.5276150703430176      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06634556346103526\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662051\n",
      "differential_evolution step 2: f(x)= -0.666023\n",
      "variance optimization tolerance of changed to:  0.06660228539251116\n",
      "Next points to be requested: \n",
      "[[9.66626859 2.52870711]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  81\n",
      "Run Time:  1.5583441257476807      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06660228539251116\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0657201816782467\n",
      "Next points to be requested: \n",
      "[[9.17888892 1.95851212]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  82\n",
      "Run Time:  1.5687873363494873      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0657201816782467\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660048\n",
      "variance optimization tolerance of changed to:  0.06600476031196384\n",
      "Next points to be requested: \n",
      "[[6.80312255 2.79895588]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  83\n",
      "Run Time:  1.588219165802002      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06600476031196384\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.062284360030253255\n",
      "Next points to be requested: \n",
      "[[4.56573393 8.61078037]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  84\n",
      "Run Time:  1.5963914394378662      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.062284360030253255\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662827\n",
      "differential_evolution step 2: f(x)= -0.662827\n",
      "differential_evolution step 3: f(x)= -0.664329\n",
      "variance optimization tolerance of changed to:  0.06643293813088606\n",
      "Next points to be requested: \n",
      "[[8.71256284 2.65045293]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  85\n",
      "Run Time:  1.632768154144287      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06643293813088606\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05947426616750076\n",
      "Next points to be requested: \n",
      "[[5.41418127 6.49090972]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  86\n",
      "Run Time:  1.6419336795806885      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05947426616750076\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.664747\n",
      "differential_evolution step 2: f(x)= -0.665015\n",
      "variance optimization tolerance of changed to:  0.06650147517315981\n",
      "Next points to be requested: \n",
      "[[9.75359415 2.87365526]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  87\n",
      "Run Time:  1.6693074703216553      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650147517315981\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0651685471730094\n",
      "Next points to be requested: \n",
      "[[9.30648134 6.36931267]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  88\n",
      "Run Time:  1.6769235134124756      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0651685471730094\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665086\n",
      "variance optimization tolerance of changed to:  0.06650863994476233\n",
      "Next points to be requested: \n",
      "[[9.28023151 2.49568505]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  89\n",
      "Run Time:  1.6960604190826416      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650863994476233\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05387044219029999\n",
      "Next points to be requested: \n",
      "[[3.94972772 0.68509712]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  90\n",
      "Run Time:  1.7064321041107178      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05387044219029999\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665881\n",
      "differential_evolution step 2: f(x)= -0.665881\n",
      "differential_evolution step 3: f(x)= -0.665881\n",
      "variance optimization tolerance of changed to:  0.06658811827175631\n",
      "Next points to be requested: \n",
      "[[9.99806627 2.3615742 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  91\n",
      "Run Time:  1.7398719787597656      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06658811827175631\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.059868771897546774\n",
      "Next points to be requested: \n",
      "[[6.62465411 7.15451271]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  92\n",
      "Run Time:  1.7488360404968262      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.059868771897546774\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663593\n",
      "differential_evolution step 2: f(x)= -0.666532\n",
      "variance optimization tolerance of changed to:  0.06665316034120797\n",
      "Next points to be requested: \n",
      "[[9.90368919 2.65968445]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  93\n",
      "Run Time:  1.7751493453979492      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665316034120797\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05301225473605417\n",
      "Next points to be requested: \n",
      "[[0.73521445 6.62437801]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  94\n",
      "Run Time:  1.7866766452789307      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05301225473605417\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662001\n",
      "differential_evolution step 2: f(x)= -0.66392\n",
      "variance optimization tolerance of changed to:  0.06639204564869815\n",
      "Next points to be requested: \n",
      "[[8.57173884 2.57927743]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  95\n",
      "Run Time:  1.8145148754119873      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06639204564869815\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06216237997415838\n",
      "Next points to be requested: \n",
      "[[5.79488506 8.3864241 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  96\n",
      "Run Time:  1.8238089084625244      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06216237997415838\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665789\n",
      "differential_evolution step 2: f(x)= -0.665789\n",
      "variance optimization tolerance of changed to:  0.06657894266682074\n",
      "Next points to be requested: \n",
      "[[9.47421171 2.63972007]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  97\n",
      "Run Time:  1.849839687347412      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657894266682074\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06311334959954433\n",
      "Next points to be requested: \n",
      "[[4.89315628 5.60229802]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  98\n",
      "Run Time:  1.858112096786499      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06311334959954433\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.6644\n",
      "variance optimization tolerance of changed to:  0.066439987480006\n",
      "Next points to be requested: \n",
      "[[8.89279567 2.5281399 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  99\n",
      "Run Time:  1.8803253173828125      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.066439987480006\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06205372201890699\n",
      "Next points to be requested: \n",
      "[[4.47032257 1.99731332]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  100\n",
      "Run Time:  1.888942003250122      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06205372201890699\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662363\n",
      "differential_evolution step 2: f(x)= -0.664334\n",
      "variance optimization tolerance of changed to:  0.0664334431076175\n",
      "Next points to be requested: \n",
      "[[8.83875849 2.74750123]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  101\n",
      "Run Time:  1.9177906513214111      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0664334431076175\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06414763470567866\n",
      "Next points to be requested: \n",
      "[[0.48885453 5.6679272 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  102\n",
      "Run Time:  1.9317312240600586      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06414763470567866\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664475\n",
      "differential_evolution step 2: f(x)= -0.664475\n",
      "variance optimization tolerance of changed to:  0.06644748998044829\n",
      "Next points to be requested: \n",
      "[[8.78633883 2.64764147]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  103\n",
      "Run Time:  1.9581880569458008      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644748998044829\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06468545864993115\n",
      "Next points to be requested: \n",
      "[[1.48641829 8.4670777 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  104\n",
      "Run Time:  1.9664762020111084      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06468545864993115\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664519\n",
      "variance optimization tolerance of changed to:  0.06645191010299234\n",
      "Next points to be requested: \n",
      "[[9.25233914 2.83168554]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  105\n",
      "Run Time:  1.9886457920074463      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06645191010299234\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06322017820736535\n",
      "Next points to be requested: \n",
      "[[6.99719384 7.72594145]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  106\n",
      "Run Time:  2.002408027648926      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06322017820736535\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663295\n",
      "differential_evolution step 2: f(x)= -0.664782\n",
      "variance optimization tolerance of changed to:  0.06647822727553665\n",
      "Next points to be requested: \n",
      "[[8.98476923 2.57799247]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  107\n",
      "Run Time:  2.060253143310547      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06647822727553665\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05564707083690532\n",
      "Next points to be requested: \n",
      "[[5.00259589 9.28562213]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  108\n",
      "Run Time:  2.0799832344055176      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05564707083690532\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.66379\n",
      "differential_evolution step 2: f(x)= -0.666366\n",
      "variance optimization tolerance of changed to:  0.06663658503751185\n",
      "Next points to be requested: \n",
      "[[9.91396814 2.48370745]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  109\n",
      "Run Time:  2.1196117401123047      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06663658503751185\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.061740005182747054\n",
      "Next points to be requested: \n",
      "[[6.85761715 1.60918306]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  110\n",
      "Run Time:  2.1330502033233643      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.061740005182747054\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665239\n",
      "variance optimization tolerance of changed to:  0.06652388526732311\n",
      "Next points to be requested: \n",
      "[[9.18862883 2.60351279]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  111\n",
      "Run Time:  2.156301498413086      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06652388526732311\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06119684294279724\n",
      "Next points to be requested: \n",
      "[[4.25305374 0.28293822]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  112\n",
      "Run Time:  2.164879083633423      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06119684294279724\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661586\n",
      "differential_evolution step 2: f(x)= -0.665121\n",
      "differential_evolution step 3: f(x)= -0.666932\n",
      "variance optimization tolerance of changed to:  0.0666931842910344\n",
      "Next points to be requested: \n",
      "[[9.85285136e+00 4.12482034e-03]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  113\n",
      "Run Time:  2.2027578353881836      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0666931842910344\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.062357896235097215\n",
      "Next points to be requested: \n",
      "[[4.4001923  2.02831934]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  114\n",
      "Run Time:  2.213435411453247      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.062357896235097215\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665655\n",
      "differential_evolution step 2: f(x)= -0.666495\n",
      "variance optimization tolerance of changed to:  0.06664953219950354\n",
      "Next points to be requested: \n",
      "[[9.86427111 2.63721964]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  115\n",
      "Run Time:  2.2456488609313965      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06664953219950354\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06316737345196341\n",
      "Next points to be requested: \n",
      "[[0.79409197 6.03193909]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  116\n",
      "Run Time:  2.254478931427002      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06316737345196341\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.66507\n",
      "differential_evolution step 2: f(x)= -0.66507\n",
      "variance optimization tolerance of changed to:  0.06650700293488024\n",
      "Next points to be requested: \n",
      "[[9.23582438 2.51216038]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  117\n",
      "Run Time:  2.2841737270355225      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06650700293488024\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06228705797350888\n",
      "Next points to be requested: \n",
      "[[5.31883027 7.80560131]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  118\n",
      "Run Time:  2.293611526489258      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06228705797350888\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665904\n",
      "differential_evolution step 2: f(x)= -0.665904\n",
      "variance optimization tolerance of changed to:  0.06659040843433192\n",
      "Next points to be requested: \n",
      "[[9.53249457 2.61900029]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  119\n",
      "Run Time:  2.3231866359710693      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06659040843433192\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06412340053288997\n",
      "Next points to be requested: \n",
      "[[8.53587121 7.77924111]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  120\n",
      "Run Time:  2.33457350730896      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06412340053288997\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662003\n",
      "differential_evolution step 2: f(x)= -0.665329\n",
      "variance optimization tolerance of changed to:  0.0665328814922906\n",
      "Next points to be requested: \n",
      "[[9.30513381 2.71390899]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  121\n",
      "Run Time:  2.3698723316192627      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0665328814922906\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05985737842769297\n",
      "Next points to be requested: \n",
      "[[0.0907966  6.38154942]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  122\n",
      "Run Time:  2.379931926727295      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05985737842769297\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666532\n",
      "differential_evolution step 2: f(x)= -0.666532\n",
      "variance optimization tolerance of changed to:  0.0666532227167627\n",
      "Next points to be requested: \n",
      "[[9.91971802 2.67260568]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  123\n",
      "Run Time:  2.423827886581421      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0666532227167627\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06161996498246508\n",
      "Next points to be requested: \n",
      "[[7.96543178 5.36112324]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  124\n",
      "Run Time:  2.464893102645874      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06161996498246508\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.664333\n",
      "differential_evolution step 2: f(x)= -0.66448\n",
      "variance optimization tolerance of changed to:  0.0664479737529823\n",
      "Next points to be requested: \n",
      "[[9.96398463 2.21452806]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  125\n",
      "Run Time:  2.506704568862915      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0664479737529823\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06440716050218326\n",
      "Next points to be requested: \n",
      "[[8.90436635 7.55002854]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  126\n",
      "Run Time:  2.5181386470794678      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06440716050218326\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.657841\n",
      "differential_evolution step 2: f(x)= -0.664608\n",
      "differential_evolution step 3: f(x)= -0.666452\n",
      "variance optimization tolerance of changed to:  0.06664515414956933\n",
      "Next points to be requested: \n",
      "[[9.83747672 2.58171301]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  127\n",
      "Run Time:  2.55167818069458      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06664515414956933\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06405092373025877\n",
      "Next points to be requested: \n",
      "[[2.81743328 8.41270253]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  128\n",
      "Run Time:  2.5606272220611572      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06405092373025877\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665247\n",
      "differential_evolution step 2: f(x)= -0.665247\n",
      "variance optimization tolerance of changed to:  0.0665247416472554\n",
      "Next points to be requested: \n",
      "[[9.19388668 2.66195653]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  129\n",
      "Run Time:  2.5899901390075684      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0665247416472554\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06342360924765666\n",
      "Next points to be requested: \n",
      "[[3.60924766 5.89637238]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  130\n",
      "Run Time:  2.603522300720215      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06342360924765666\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661228\n",
      "differential_evolution step 2: f(x)= -0.664465\n",
      "variance optimization tolerance of changed to:  0.06644653377254653\n",
      "Next points to be requested: \n",
      "[[9.47885966 0.10002415]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  131\n",
      "Run Time:  2.6372783184051514      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644653377254653\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06554952297647855\n",
      "Next points to be requested: \n",
      "[[5.37614068 2.5055016 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  132\n",
      "Run Time:  2.6458349227905273      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06554952297647855\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.659491\n",
      "differential_evolution step 2: f(x)= -0.659491\n",
      "variance optimization tolerance of changed to:  0.0659491062297075\n",
      "Next points to be requested: \n",
      "[[6.3457563  2.70862245]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  133\n",
      "Run Time:  2.6731116771698      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0659491062297075\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.062145762193290294\n",
      "Next points to be requested: \n",
      "[[1.74413041 0.05593426]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  134\n",
      "Run Time:  2.682474374771118      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.062145762193290294\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.665171\n",
      "differential_evolution step 2: f(x)= -0.665171\n",
      "variance optimization tolerance of changed to:  0.06651711385127916\n",
      "Next points to be requested: \n",
      "[[9.1875945 2.5683194]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  135\n",
      "Run Time:  2.710596799850464      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06651711385127916\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.03846554620662063\n",
      "Next points to be requested: \n",
      "[[1.2691909  1.22430048]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  136\n",
      "Run Time:  2.7289798259735107      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.03846554620662063\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666172\n",
      "differential_evolution step 2: f(x)= -0.666172\n",
      "variance optimization tolerance of changed to:  0.06661717265191623\n",
      "Next points to be requested: \n",
      "[[9.77239614 2.70903124]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  137\n",
      "Run Time:  2.7600152492523193      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06661717265191623\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06366673013165007\n",
      "Next points to be requested: \n",
      "[[2.27390459 3.20372573]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  138\n",
      "Run Time:  2.7701046466827393      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06366673013165007\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666433\n",
      "differential_evolution step 2: f(x)= -0.666433\n",
      "variance optimization tolerance of changed to:  0.06664328617779183\n",
      "Next points to be requested: \n",
      "[[9.83836407 2.56420176]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  139\n",
      "Run Time:  2.798203468322754      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06664328617779183\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06309227815182603\n",
      "Next points to be requested: \n",
      "[[0.         6.09985759]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  140\n",
      "Run Time:  2.8083620071411133      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06309227815182603\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664183\n",
      "differential_evolution step 2: f(x)= -0.665415\n",
      "variance optimization tolerance of changed to:  0.06654153820281923\n",
      "Next points to be requested: \n",
      "[[9.63175364 2.41794698]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  141\n",
      "Run Time:  2.841219425201416      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06654153820281923\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0634730576481377\n",
      "Next points to be requested: \n",
      "[[7.16432857 7.85495011]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  142\n",
      "Run Time:  2.85713791847229      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0634730576481377\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660593\n",
      "differential_evolution step 2: f(x)= -0.663755\n",
      "variance optimization tolerance of changed to:  0.06637554169157767\n",
      "Next points to be requested: \n",
      "[[9.40039169 2.29898476]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  143\n",
      "Run Time:  2.898594856262207      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06637554169157767\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0614985758970291\n",
      "Next points to be requested: \n",
      "[[5.62951358 8.51594738]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  144\n",
      "Run Time:  2.9166102409362793      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0614985758970291\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666529\n",
      "differential_evolution step 2: f(x)= -0.666529\n",
      "variance optimization tolerance of changed to:  0.06665289749351577\n",
      "Next points to be requested: \n",
      "[[9.89135094 2.64832182]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  145\n",
      "Run Time:  2.973386287689209      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665289749351577\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06272470476397286\n",
      "Next points to be requested: \n",
      "[[5.25376034 3.4499397 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  146\n",
      "Run Time:  3.0158023834228516      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06272470476397286\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.654696\n",
      "differential_evolution step 2: f(x)= -0.665451\n",
      "variance optimization tolerance of changed to:  0.06654507422980903\n",
      "Next points to be requested: \n",
      "[[9.48404278 0.0367531 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  147\n",
      "Run Time:  3.0466129779815674      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06654507422980903\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06617506394471827\n",
      "Next points to be requested: \n",
      "[[8.03796985 2.45596042]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  148\n",
      "Run Time:  3.0565664768218994      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06617506394471827\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666604\n",
      "differential_evolution step 2: f(x)= -0.666604\n",
      "variance optimization tolerance of changed to:  0.06666039939059555\n",
      "Next points to be requested: \n",
      "[[9.94571015 2.65982371]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  149\n",
      "Run Time:  3.08486270904541      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06666039939059555\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06294178301476018\n",
      "Next points to be requested: \n",
      "[[0.22488461 0.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  150\n",
      "Run Time:  3.094684600830078      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06294178301476018\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.66164\n",
      "differential_evolution step 2: f(x)= -0.662618\n",
      "differential_evolution step 3: f(x)= -0.662868\n",
      "variance optimization tolerance of changed to:  0.0662868079258672\n",
      "Next points to be requested: \n",
      "[[8.81503686 2.36776214]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  151\n",
      "Run Time:  3.1410670280456543      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0662868079258672\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06471777639500977\n",
      "Next points to be requested: \n",
      "[[0.871978   9.03219188]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  152\n",
      "Run Time:  3.151252508163452      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06471777639500977\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.661618\n",
      "variance optimization tolerance of changed to:  0.06616178197433868\n",
      "Next points to be requested: \n",
      "[[9.92772943 3.10849111]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  153\n",
      "Run Time:  3.1730034351348877      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06616178197433868\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06420119103584794\n",
      "Next points to be requested: \n",
      "[[8.82481329 1.35941269]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  154\n",
      "Run Time:  3.184849500656128      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06420119103584794\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665941\n",
      "variance optimization tolerance of changed to:  0.06659412772103081\n",
      "Next points to be requested: \n",
      "[[9.58719162 2.55774368]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  155\n",
      "Run Time:  3.2134058475494385      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06659412772103081\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06298256276950982\n",
      "Next points to be requested: \n",
      "[[2.25319007 0.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  156\n",
      "Run Time:  3.2251904010772705      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06298256276950982\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665406\n",
      "variance optimization tolerance of changed to:  0.06654062456708475\n",
      "Next points to be requested: \n",
      "[[9.5811689  2.79290448]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  157\n",
      "Run Time:  3.2820370197296143      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06654062456708475\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05916580965004739\n",
      "Next points to be requested: \n",
      "[[4.18647051 3.6543641 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  158\n",
      "Run Time:  3.295301914215088      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05916580965004739\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 2: f(x)= -0.665666\n",
      "variance optimization tolerance of changed to:  0.06656656246568902\n",
      "Next points to be requested: \n",
      "[[9.42354786 2.58066438]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  159\n",
      "Run Time:  3.3241400718688965      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06656656246568902\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06027396178335566\n",
      "Next points to be requested: \n",
      "[[4.1682303  0.34192972]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  160\n",
      "Run Time:  3.339287281036377      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06027396178335566\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666593\n",
      "differential_evolution step 2: f(x)= -0.666593\n",
      "variance optimization tolerance of changed to:  0.0666593406596873\n",
      "Next points to be requested: \n",
      "[[9.9139424  2.58393712]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  161\n",
      "Run Time:  3.404175281524658      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0666593406596873\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0652739516390598\n",
      "Next points to be requested: \n",
      "[[5.1930171  3.01841156]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  162\n",
      "Run Time:  3.4156973361968994      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0652739516390598\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665714\n",
      "differential_evolution step 2: f(x)= -0.665714\n",
      "variance optimization tolerance of changed to:  0.06657144305342824\n",
      "Next points to be requested: \n",
      "[[9.9027665  0.10754123]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  163\n",
      "Run Time:  3.4527361392974854      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657144305342824\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06376929368115063\n",
      "Next points to be requested: \n",
      "[[0.55309062 5.5270606 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  164\n",
      "Run Time:  3.463932514190674      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06376929368115063\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666268\n",
      "differential_evolution step 2: f(x)= -0.666268\n",
      "variance optimization tolerance of changed to:  0.06662677767871049\n",
      "Next points to be requested: \n",
      "[[9.8286185  2.70922255]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  165\n",
      "Run Time:  3.4965341091156006      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06662677767871049\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06350306558655026\n",
      "Next points to be requested: \n",
      "[[1.23355859 8.12843318]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  166\n",
      "Run Time:  3.5152368545532227      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06350306558655026\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.665462\n",
      "differential_evolution step 2: f(x)= -0.666501\n",
      "variance optimization tolerance of changed to:  0.06665009027397903\n",
      "Next points to be requested: \n",
      "[[9.71429057e+00 9.03109455e-03]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  167\n",
      "Run Time:  3.5534615516662598      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665009027397903\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06226282632089933\n",
      "Next points to be requested: \n",
      "[[6.6571595  8.26887649]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  168\n",
      "Run Time:  3.5641939640045166      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06226282632089933\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665718\n",
      "variance optimization tolerance of changed to:  0.06657175234410927\n",
      "Next points to be requested: \n",
      "[[9.52910053 2.519981  ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  169\n",
      "Run Time:  3.587847948074341      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06657175234410927\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.060888749159751336\n",
      "Next points to be requested: \n",
      "[[0.56243804 6.27813109]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  170\n",
      "Run Time:  3.5990793704986572      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.060888749159751336\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664731\n",
      "differential_evolution step 2: f(x)= -0.664731\n",
      "differential_evolution step 3: f(x)= -0.664731\n",
      "variance optimization tolerance of changed to:  0.06647312555524544\n",
      "Next points to be requested: \n",
      "[[9.45698394 2.84888826]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  171\n",
      "Run Time:  3.63655424118042      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06647312555524544\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06621170150969972\n",
      "Next points to be requested: \n",
      "[[8.87177904 0.10657312]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  172\n",
      "Run Time:  3.6474738121032715      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06621170150969972\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.665821\n",
      "differential_evolution step 2: f(x)= -0.665821\n",
      "variance optimization tolerance of changed to:  0.06658211597507267\n",
      "Next points to be requested: \n",
      "[[9.49017174 2.63601719]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  173\n",
      "Run Time:  3.682194948196411      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06658211597507267\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06446146250709997\n",
      "Next points to be requested: \n",
      "[[0.89956019 9.14759144]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  174\n",
      "Run Time:  3.6925182342529297      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06446146250709997\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663307\n",
      "differential_evolution step 2: f(x)= -0.663307\n",
      "variance optimization tolerance of changed to:  0.0663306661398554\n",
      "Next points to be requested: \n",
      "[[8.28700653 2.5798397 ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  175\n",
      "Run Time:  3.7265429496765137      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.0663306661398554\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06280865470679407\n",
      "Next points to be requested: \n",
      "[[1.61923112 6.04362053]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  176\n",
      "Run Time:  3.7383525371551514      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06280865470679407\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664244\n",
      "differential_evolution step 2: f(x)= -0.664244\n",
      "variance optimization tolerance of changed to:  0.06642444409705545\n",
      "Next points to be requested: \n",
      "[[8.68422891 2.68459389]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  177\n",
      "Run Time:  3.767888069152832      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642444409705545\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0628051984370351\n",
      "Next points to be requested: \n",
      "[[1.42303725 0.        ]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  178\n",
      "Run Time:  3.779985189437866      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0628051984370351\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666778\n",
      "differential_evolution step 2: f(x)= -0.666778\n",
      "differential_evolution step 3: f(x)= -0.666778\n",
      "variance optimization tolerance of changed to:  0.06667779788121568\n",
      "Next points to be requested: \n",
      "[[9.92861431 0.03197068]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  179\n",
      "Run Time:  3.817293643951416      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06667779788121568\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06342723922587504\n",
      "Next points to be requested: \n",
      "[[0.64366813 5.99844417]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  180\n",
      "Run Time:  3.8264713287353516      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06342723922587504\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663935\n",
      "differential_evolution step 2: f(x)= -0.665232\n",
      "variance optimization tolerance of changed to:  0.06652323465157206\n",
      "Next points to be requested: \n",
      "[[9.38704355 2.76638554]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  181\n",
      "Run Time:  3.855900526046753      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06652323465157206\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.0626767888277225\n",
      "Next points to be requested: \n",
      "[[3.19655022 8.01576706]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  182\n",
      "Run Time:  3.867997407913208      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.0626767888277225\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.663443\n",
      "differential_evolution step 2: f(x)= -0.665567\n",
      "variance optimization tolerance of changed to:  0.06655672242975509\n",
      "Next points to be requested: \n",
      "[[9.38003248 2.57334178]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  183\n",
      "Run Time:  3.92969012260437      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06655672242975509\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variance optimization tolerance of changed to:  0.06236490341470984\n",
      "Next points to be requested: \n",
      "[[5.78260577 8.35148309]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  184\n",
      "Run Time:  3.9569475650787354      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06236490341470984\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664684\n",
      "differential_evolution step 2: f(x)= -0.664684\n",
      "differential_evolution step 3: f(x)= -0.666569\n",
      "variance optimization tolerance of changed to:  0.06665694935290058\n",
      "Next points to be requested: \n",
      "[[9.89668907 2.60629343]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  185\n",
      "Run Time:  3.9924557209014893      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06665694935290058\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06048334632261292\n",
      "Next points to be requested: \n",
      "[[3.69889552 3.53881735]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  186\n",
      "Run Time:  4.008392572402954      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06048334632261292\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.660634\n",
      "differential_evolution step 2: f(x)= -0.663608\n",
      "variance optimization tolerance of changed to:  0.06636082049711355\n",
      "Next points to be requested: \n",
      "[[9.57759961 0.17609204]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  187\n",
      "Run Time:  4.037184953689575      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06636082049711355\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06484367370026344\n",
      "Next points to be requested: \n",
      "[[2.59574216 3.00859216]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  188\n",
      "Run Time:  4.048826217651367      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06484367370026344\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664434\n",
      "variance optimization tolerance of changed to:  0.06644342233914087\n",
      "Next points to be requested: \n",
      "[[9.10186903 0.02526848]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  189\n",
      "Run Time:  4.071019411087036      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06644342233914087\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06287141664318849\n",
      "Next points to be requested: \n",
      "[[2.19007639 8.05457544]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  190\n",
      "Run Time:  4.08373761177063      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06287141664318849\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664388\n",
      "differential_evolution step 2: f(x)= -0.664388\n",
      "variance optimization tolerance of changed to:  0.06643884127765903\n",
      "Next points to be requested: \n",
      "[[8.76036682 2.60755183]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  191\n",
      "Run Time:  4.11801815032959      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06643884127765903\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05736630566879134\n",
      "Next points to be requested: \n",
      "[[5.65421317 0.96594324]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  192\n",
      "Run Time:  4.129374980926514      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.05736630566879134\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "differential_evolution step 1: f(x)= -0.665881\n",
      "differential_evolution step 2: f(x)= -0.666289\n",
      "differential_evolution step 3: f(x)= -0.666289\n",
      "variance optimization tolerance of changed to:  0.06662891484381699\n",
      "Next points to be requested: \n",
      "[[9.77243647 2.66671667]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  193\n",
      "Run Time:  4.170217752456665      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06662891484381699\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06397836343694828\n",
      "Next points to be requested: \n",
      "[[9.64360267 7.95015297]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  194\n",
      "Run Time:  4.185134172439575      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06397836343694828\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.666163\n",
      "differential_evolution step 2: f(x)= -0.666163\n",
      "variance optimization tolerance of changed to:  0.06661633677162924\n",
      "Next points to be requested: \n",
      "[[9.68607552 2.57660405]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  195\n",
      "Run Time:  4.213635683059692      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06661633677162924\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06508370016424876\n",
      "Next points to be requested: \n",
      "[[3.70833096 2.45597592]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  196\n",
      "Run Time:  4.223982810974121      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06508370016424876\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.664279\n",
      "differential_evolution step 2: f(x)= -0.664279\n",
      "variance optimization tolerance of changed to:  0.06642790965540944\n",
      "Next points to be requested: \n",
      "[[9.47683326 2.89531618]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  197\n",
      "Run Time:  4.25578236579895      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06642790965540944\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.06389931253011626\n",
      "Next points to be requested: \n",
      "[[1.06493576 5.83039207]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  198\n",
      "Run Time:  4.284764051437378      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  global\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  global\n",
      "adjusted tolerance:  0.06389931253011626\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "differential_evolution step 1: f(x)= -0.662809\n",
      "differential_evolution step 2: f(x)= -0.663584\n",
      "variance optimization tolerance of changed to:  0.06635836919474646\n",
      "Next points to be requested: \n",
      "[[9.15066976 2.90271859]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "\n",
      "\n",
      "\n",
      "====================\n",
      "====================\n",
      "iteration:  199\n",
      "Run Time:  4.340045928955078      seconds\n",
      "Number of measurements:  10\n",
      "====================\n",
      "aks() initiated with hyperparameters: [0.456661   5.43574411 0.83448989]\n",
      "optimization method:  local\n",
      "bounds:  None\n",
      "====================================\n",
      "finding acquisition function maxima...\n",
      "optimization method  local\n",
      "adjusted tolerance:  0.06635836919474646\n",
      "population size:  20\n",
      "maximum number of iterations:  20\n",
      "bounds: \n",
      "[[ 0 10]\n",
      " [ 0 10]]\n",
      "cost function parameters:  {}\n",
      "====================================\n",
      "variance optimization tolerance of changed to:  0.05750263864169297\n",
      "Next points to be requested: \n",
      "[[5.73673197 8.94734515]]\n",
      "CAUTION: you have not provided data variances,\n",
      "they will set to be 1 percent of the the data values!\n",
      "Async Hyper-parameter update not successful. I am keeping the old ones.\n",
      "That probbaly means you are not optimizing them asynchronously\n",
      "hyperparameters:  [0.456661   5.43574411 0.83448989]\n",
      "No training in this round but I tried to update the hyperparameters\n",
      "====================================================\n",
      "The autonomous experiment was concluded successfully\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "#/usr/bin/env python\n",
    "import numpy as np\n",
    "from gpcam.autonomous_experimenter import AutonomousExperimenterfvGP\n",
    "\n",
    "def instrument(data):\n",
    "    for entry in data:\n",
    "        entry[\"value\"] = np.array([np.sin(np.linalg.norm(entry[\"position\"])),np.sin(np.linalg.norm(entry[\"position\"]))])\n",
    "    return data\n",
    "\n",
    "my_fvae = AutonomousExperimenterfvGP(np.array([[0,10],[0,10]]),2,1,\n",
    "                                     instrument,np.ones((3)),np.array([[0.001,100],[0.001,100],[0.001,100]]),\n",
    "                                     init_dataset_size= 10)\n",
    "my_fvae.train()\n",
    "input(\"training done\")\n",
    "my_ae.go(N = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-willow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-morning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
