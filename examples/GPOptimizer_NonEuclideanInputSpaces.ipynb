{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2377d373",
   "metadata": {},
   "source": [
    "# GPs on Non-Euclidean Input Spaces\n",
    "GPs on non-Euclidean input spaces have become more and more relevant in recent years, especially for Bayesian Optimization in chemistry. gpCAM can be used for that purpose as long as a correct kernel is defined. Of course, if mean and noise functions are also provided, they have to operate on these non-Euclidean spaces as well. \n",
    "\n",
    "In this example, we run a small GP on words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install the newest version of gpcam\n",
    "#!pip install gpcam==8.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5399565",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gpcam import GPOptimizer\n",
    "from dask.distributed import Client\n",
    "from gpcam.gp_kernels import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91e69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the x_data a set will allow us to put any objects or structures into it.\n",
    "x_data = [('hello'),('world'),('this'),('is'),('gpcam')]\n",
    "y_data = np.array([2.,1.9,1.8,3.0,5.])\n",
    "\n",
    "\n",
    "def string_distance(string1, string2):\n",
    "    difference = abs(len(string1) - len(string2))\n",
    "    common_length = min(len(string1),len(string2))\n",
    "    string1 = string1[0:common_length]\n",
    "    string2 = string2[0:common_length]\n",
    "    \n",
    "    for i in range(len(string1)):\n",
    "        if string1[i] != string2[i]:\n",
    "            difference += 1.\n",
    "\n",
    "    return difference\n",
    "\n",
    "\n",
    "def kernel(x1,x2,hps,obj):\n",
    "    d = np.zeros((len(x1),len(x2)))\n",
    "    count1 = 0\n",
    "    for string1 in x1:\n",
    "        count2 = 0\n",
    "        for string2 in x2:\n",
    "            d[count1,count2] = string_distance(string1,string2)\n",
    "            count2 += 1\n",
    "        count1 += 1\n",
    "    return hps[0] * matern_kernel_diff1(d,hps[1])\n",
    "    \n",
    "\n",
    "\n",
    "my_gp = GPOptimizer(x_data,y_data, init_hyperparameters=np.ones((2)),\n",
    "                    gp_kernel_function=kernel, info = True)\n",
    "bounds = np.array([[0.001,100.],[0.001,100]])\n",
    "my_gp.train(hyperparameter_bounds=bounds)\n",
    "\n",
    "print(\"hyperparameters: \", my_gp.hyperparameters)\n",
    "print(\"prediction : \",my_gp.posterior_mean(['full'])[\"f(x)\"])\n",
    "print(\"uncertainty: \",np.sqrt(my_gp.posterior_covariance(['full'])[\"v(x)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5644ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##which one should I measure next?\n",
    "my_gp.ask([('hello'),('world'),(\"it\"),(\"is\"),(\"me\")], n = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f9ed9f-475f-4db6-bb7d-18b3f61bf7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
