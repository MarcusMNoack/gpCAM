{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7e13ed9",
   "metadata": {},
   "source": [
    "# gpOptimizer Multi-Task Test\n",
    "At first we have to install the newest version of gpCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ec2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##first, install the newest version of gpcam\n",
    "#!pip install gpCAM==8.1.13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49d7d1",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac77ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gpcam import fvGPOptimizer\n",
    "import plotly.graph_objects as go\n",
    "from itertools import product\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293e63b7-11ae-4189-a838-b467b619b831",
   "metadata": {},
   "source": [
    "## Simple 1d Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb1cdb2-0f32-4f77-aad8-15b47d2a972c",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695bd1b-a4b5-4ac1-8de0-b7a1776a35b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x): return 0.5 * x\n",
    "def f2(x): return (-.25 * x) - 1.\n",
    "\n",
    "x_pred1d = np.linspace(0,1,50)\n",
    "plt.plot(x_pred1d,f1(x_pred1d))\n",
    "plt.plot(x_pred1d,f2(x_pred1d))\n",
    "x_data = np.random.rand(10)\n",
    "y_data1 = f1(x_data) + np.random.uniform(low = -0.01, high = 0.01, size =len(x_data))\n",
    "y_data2 = f2(x_data) + np.random.uniform(low = -0.01, high = 0.01, size =len(x_data))\n",
    "plt.scatter(x_data,y_data1) \n",
    "plt.scatter(x_data,y_data2) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b57e26-738e-4200-8d54-287f303feae0",
   "metadata": {},
   "source": [
    "### GP initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ecbb36-15d3-4756-b389-7e37c311db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gp2 = fvGPOptimizer(x_data.reshape(len(x_data),1), np.column_stack([y_data1, y_data2]))\n",
    "print(\"Hybrid Training in progress\")\n",
    "my_gp2.train(max_iter = 20, method = \"hgdl\")\n",
    "\n",
    "print(\"MCMC Training in progress\")\n",
    "my_gp2.train(max_iter = 20, method = \"mcmc\")\n",
    "\n",
    "print(\"Local Training in progress\")\n",
    "my_gp2.train(max_iter = 20, method = \"local\")\n",
    "\n",
    "print(\"Local Training in progress\")\n",
    "my_gp2.train(max_iter = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919577c-a348-4da1-8fbb-a777c355d2b4",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850610f2-67d4-4a37-987e-9793418e74d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and standard deviation\n",
    "mean = my_gp2.posterior_mean(x_pred=x_pred1d.reshape(50,1), x_out=np.array([0,1]))[\"f(x)\"]\n",
    "std = np.sqrt(my_gp2.posterior_covariance(x_pred=x_pred1d.reshape(50,1), x_out=np.array([0,1]))[\"v(x)\"])\n",
    "\n",
    "plt.plot(x_pred1d.reshape(50,1),mean[:,0], label = \"mean task 1\")\n",
    "plt.plot(x_pred1d.reshape(50,1),mean[:,1], label = \"mean task 2\")\n",
    "plt.scatter(x_data,y_data1) \n",
    "plt.scatter(x_data,y_data2) \n",
    "plt.plot(x_pred1d,f1(x_pred1d), label = \"task 1 ground truth\")\n",
    "plt.plot(x_pred1d,f2(x_pred1d), label = \"task 2 ground truth\")\n",
    "plt.fill_between(x_pred1d, mean[:,0] - 3. * std[:,0], mean[:,0] + 3. * std[:,0], alpha = 0.5, color = \"grey\")\n",
    "plt.fill_between(x_pred1d, mean[:,1] - 3. * std[:,1], mean[:,1] + 3. * std[:,1], alpha = 0.5, color = \"grey\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e7814-3988-4465-a1d1-7fdb6c7fd55b",
   "metadata": {},
   "source": [
    "### ask()ing for new actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4646e9-18cc-4bd6-bea7-1696598f1f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#asking for the best candidate:\n",
    "my_gp2.ask([np.array([0.0]), np.array([0.2]), np.array([1.])], x_out = np.array([0,1]), n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fd6db6-fa1d-4eb3-b716-f7293812161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#asking for an optimized result\n",
    "my_gp2.ask(np.array([[0.,1.]]), n=2, method = \"hgdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01cd990-3723-4afd-b69b-fa61b9066510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#more ask()s to test:\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 1, acquisition_function = 'relative information entropy set', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 1, acquisition_function = 'relative information entropy', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 1, acquisition_function = 'variance', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 1, acquisition_function = 'total correlation', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 4, acquisition_function = 'relative information entropy set', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 5, acquisition_function = 'relative information entropy', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 6, acquisition_function = 'variance', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0.,1.]]), n = 2, acquisition_function = 'total correlation', x_out = np.array([0.,1.,2.]), vectorized = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523c1cc-c018-418b-b60b-f8716e70b0a2",
   "metadata": {},
   "source": [
    "## Communicating data points with missing tasks as lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881b134-21e5-4c0b-a6df-aa6c0917b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = np.column_stack([y_data1, y_data2])\n",
    "noise_variances = np.zeros(y_data.shape) + 0.01\n",
    "y_data[2,0] = np.nan\n",
    "noise_variances[2,0] = np.nan\n",
    "\n",
    "y_data[6,1] = np.nan\n",
    "noise_variances[6,1] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "my_gp2 = fvGPOptimizer(x_data.reshape(len(x_data),1), y_data, noise_variances=noise_variances)\n",
    "print(\"Global Training in progress\")\n",
    "my_gp2.train(max_iter = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b59fc7-ade5-46ea-a6e9-36fbe92798ef",
   "metadata": {},
   "source": [
    "# 3d Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c7a6f7",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2133fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"./data/sim_variable_mod.npy\")\n",
    "sparsification = 32\n",
    "\n",
    "x_data3 = data[:,5:][::sparsification]\n",
    "y_data3 = data[:,0:3][::sparsification]\n",
    "\n",
    "#it is good practice to check the format of the data\n",
    "print(x_data3.shape)\n",
    "print(y_data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43205bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(30,100,100)\n",
    "y = np.linspace(40,130,100)\n",
    "x_pred3D = np.asarray(list(product(x, y)))\n",
    "x_pred3D = np.column_stack([x_pred3D, np.zeros((len(x_pred3D),1)) + 300.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b956f9",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x,y,z,size=3, color = 1):\n",
    "    #if not color: color = z\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter3d(x=x, y=y, z=z,mode='markers',marker=dict(color=color, size = size)))\n",
    "    \n",
    "    \n",
    "    fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c94297",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(x_data3[:,0],x_data3[:,1],x_data3[:,2], size = 5, color = y_data3[:,0])\n",
    "scatter(x_data3[:,0],x_data3[:,1],x_data3[:,2], size = 5, color = y_data3[:,1])\n",
    "scatter(x_data3[:,0],x_data3[:,1],x_data3[:,2], size = 5, color = y_data3[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650f1268",
   "metadata": {},
   "source": [
    "### A simple kernel definition\n",
    "It is vital in the multi-task case to think hard about kernel design. The kernel is now a function\n",
    "over X x X x T x T, where X is the input and T is the output space. Print the input into the kernel, it will have the dimensionality of this cartesian product space. The default kernel is just a Matern kernel in input and output directions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94379422",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As imple kernel, that won't lead to good performance because its stationary\n",
    "def mkernel(x1,x2,hps,obj):\n",
    "    d = obj.get_distance_matrix(x1,x2)\n",
    "    return hps[0] * obj.matern_kernel_diff1(d,hps[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a2f49",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c893dde8-9100-4fff-857b-eaa117809e24",
   "metadata": {},
   "source": [
    "#### (a) Default behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab03c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fvgp import fvGP\n",
    "\n",
    "my_gp2 = fvGPOptimizer(x_data3,y_data3)\n",
    "print(\"Global Training in progress\")\n",
    "my_gp2.train(max_iter = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0107eedc-4715-415a-909a-c84dab5c6493",
   "metadata": {},
   "source": [
    "#### (b) Simple custom kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8eea8f-b76a-467c-9e1f-2e7c269812fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A simple kernel, that won't lead to good performance because it's stationary\n",
    "from gpcam.gp_kernels import *\n",
    "def mkernel(x1,x2,hps):\n",
    "    d = get_distance_matrix(x1,x2)\n",
    "    return hps[0] * matern_kernel_diff1(d,hps[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc448137-38e1-4820-9e6b-b27b05047a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_gp2 = fvGPOptimizer(x_data3,y_data3,\n",
    "              init_hyperparameters=np.ones((2)), gp_kernel_function=mkernel\n",
    "             )\n",
    "print(\"Global Training in progress\")\n",
    "\n",
    "\n",
    "bounds = np.array([[0.01,1.],[0.01,1.]])\n",
    "my_gp2.train(hyperparameter_bounds=bounds,max_iter = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32d655-121e-44e5-95a2-9f55ee6987d4",
   "metadata": {},
   "source": [
    "#### (c) Deep kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d09b3-d05f-43c8-a1c6-1761a837f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpcam.deep_kernel_network import *\n",
    "iset_dim = 4\n",
    "gp_deep_kernel_layer_width = 5\n",
    "n = Network(iset_dim, gp_deep_kernel_layer_width)\n",
    "print(n.number_of_hps)\n",
    "\n",
    "def deep_multi_task_kernel(x1, x2, hps):  # pragma: no cover\n",
    "    signal_var = hps[0]\n",
    "    length_scale = hps[1]\n",
    "    hps_nn = hps[2:]\n",
    "    w1_indices = np.arange(0, gp_deep_kernel_layer_width * iset_dim)\n",
    "    last = gp_deep_kernel_layer_width * iset_dim\n",
    "    w2_indices = np.arange(last, last + gp_deep_kernel_layer_width ** 2)\n",
    "    last = last + gp_deep_kernel_layer_width ** 2\n",
    "    w3_indices = np.arange(last, last + gp_deep_kernel_layer_width * iset_dim)\n",
    "    last = last + gp_deep_kernel_layer_width * iset_dim\n",
    "    b1_indices = np.arange(last, last + gp_deep_kernel_layer_width)\n",
    "    last = last + gp_deep_kernel_layer_width\n",
    "    b2_indices = np.arange(last, last + gp_deep_kernel_layer_width)\n",
    "    last = last + gp_deep_kernel_layer_width\n",
    "    b3_indices = np.arange(last, last + iset_dim)\n",
    "\n",
    "    n.set_weights(hps_nn[w1_indices].reshape(gp_deep_kernel_layer_width, iset_dim),\n",
    "                  hps_nn[w2_indices].reshape(gp_deep_kernel_layer_width, gp_deep_kernel_layer_width),\n",
    "                  hps_nn[w3_indices].reshape(iset_dim, gp_deep_kernel_layer_width))\n",
    "    n.set_biases(hps_nn[b1_indices].reshape(gp_deep_kernel_layer_width),\n",
    "                 hps_nn[b2_indices].reshape(gp_deep_kernel_layer_width),\n",
    "                 hps_nn[b3_indices].reshape(iset_dim))\n",
    "    x1_nn = n.forward(x1)\n",
    "    x2_nn = n.forward(x2)\n",
    "    d = get_distance_matrix(x1_nn, x2_nn)\n",
    "    k = signal_var * matern_kernel_diff1(d, length_scale)\n",
    "    return k\n",
    "\n",
    "\n",
    "my_gp2 = fvGPOptimizer(x_data3,y_data3,\n",
    "              init_hyperparameters=np.ones((n.number_of_hps+2)), gp_kernel_function=deep_multi_task_kernel\n",
    "             )\n",
    "print(\"Global Training in progress\")\n",
    "\n",
    "\n",
    "bounds = np.zeros((n.number_of_hps+2,2))\n",
    "bounds[0] = np.array([0.001,10.])\n",
    "bounds[1] = np.array([0.001,10.])\n",
    "bounds[2:] = np.array([-1,1])\n",
    "my_gp2.train(hyperparameter_bounds=bounds,max_iter = 2, method = \"mcmc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda3d35",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = my_gp2.posterior_mean(x_pred3D, x_out = np.array([0.,1.,2.]))[\"f(x)\"]\n",
    "var =  my_gp2.posterior_covariance(x_pred3D, x_out = np.array([0.,1.,2.]))[\"v(x)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f6da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract data point to compare to:\n",
    "index300 = np.where(x_data3[:,2]==300.)\n",
    "imageX_data = x_data3[index300]\n",
    "imageY_data = y_data3[index300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabb5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=x_pred3D[:,0],y=x_pred3D[:,1], z=mean[:,0],\n",
    "                             mode='markers',marker=dict(color=mean[:,0], size = 5)))\n",
    "fig.add_trace(go.Scatter3d(x=imageX_data[:,0], y=imageX_data[:,1] , z=imageY_data[:,0],\n",
    "                           mode='markers',marker=dict(color=imageY_data[:,0], size = 5)))\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=x_pred3D[:,0], y=x_pred3D[:,1], z=mean[:,1],\n",
    "                           mode='markers',marker=dict(color=mean[:,1], size = 5)))\n",
    "fig.add_trace(go.Scatter3d(x=imageX_data[:,0], y=imageX_data[:,1], z=imageY_data[:,1],\n",
    "                           mode='markers',marker=dict(color=imageY_data[:,1], size = 5)))\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=x_pred3D[:,0], y=x_pred3D[:,1], z=mean[:,2],\n",
    "                           mode='markers',marker=dict(color=mean[:,2], size = 5)))\n",
    "fig.add_trace(go.Scatter3d(x=imageX_data[:,0], y=imageX_data[:,1], z=imageY_data[:,2],\n",
    "                           mode='markers',marker=dict(color=imageY_data[:,2], size = 5)))\n",
    "fig.update_layout(autosize=False,\n",
    "                  width=800, height=800,\n",
    "                  font=dict(size=18,),\n",
    "                  margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd39be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"n=1\")\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 1, max_iter=2,pop_size=2, info = True,\n",
    "           acquisition_function = 'relative information entropy set', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 1, max_iter=2,pop_size=2, info = True,\n",
    "           acquisition_function = 'relative information entropy', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 1, max_iter=2,pop_size=2,info = True,\n",
    "           acquisition_function = 'variance', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 1, max_iter=2,pop_size=2,info = True,\n",
    "           acquisition_function = 'total correlation', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "\n",
    "print(\"n>1\")\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 4, max_iter=2,pop_size=2,info = True,\n",
    "           acquisition_function = 'relative information entropy set', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 5, max_iter=2,pop_size=2,info = True,\n",
    "           acquisition_function = 'relative information entropy', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 3, max_iter=2,pop_size=2,info = True,\n",
    "           acquisition_function = 'variance', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "my_gp2.ask(np.array([[0,1],[0,1],[0,1]]), n = 2, max_iter=2,pop_size=2,info = True,\n",
    "           acquisition_function = 'total correlation', x_out = np.array([0.,1.,2.]), vectorized = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3de884-ad7c-4756-ae32-09826122bb84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd56557-e206-4b6d-b0d7-9a8021e007fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
